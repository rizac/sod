# configuration for creating and optionally evaluating a model

# whether to remove na before training and testing (this might lead to slightly different
# number of rows of the confusion matrices of the evaluations, and in the number of rows
# of the prediction hdf files)
drop_na: true

# Parameters to test the model files. Already existing models will NOT be re-created, saving time
test:
  filename: 'allset_test.hdf'  # null (no test, just create the models), or the test set to predict (HDF format) relative to the 'datasets' directory
  columns2save:  # The columns of the input test above to be saved from each predictions
    - 'Segment.db.id'  # the segment id
    - 'dataset_id'     # int (int8 could be used)
    - 'station_id'     # int
    - 'channel_code'   # str (categorical)
    - 'location_code'  # str (categorical)
    - 'window_type'    # bool
    - 'event_time'     # datetime
    - 'hand_labelled'  # bool
    - 'outlier'        # bool
  categorical_columns:  # the columns of the input test above to be converted as categorical when opening
    - 'channel_code'    # set to null to ignore
    - 'location_code'

# Parameters to create the model files. Already existing models will NOT be re-created, saving time
training:
  classifier:
    classname: "sklearn.ensemble.iforest.IsolationForest"  # The model, in the form of a Python path to the classifier object
    parameters:  # The classifier parameters to iterate over:
      n_estimators:
        - 50
        - 100
        - 200
      max_samples:
        - 512
        # - 1024
        - 2048
        # - 4096
        - 8192
      contamination:
        - 'auto'
      behaviour:
        - 'new'
      random_state:
        - 42
  input:
    filename: 'allset_train.hdf'  # the training set (HDF format relative to the 'datasets' directory)
    features:  # The input features (pandas dataframe columns) to iterate over:
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
      -
        - "psd@0.2sec"
        - "psd@1sec"
      -
        - "psd@0.2sec"
        - "psd@2sec"
      -
        - "psd@0.2sec"
        - "psd@5sec"
      -
        - "psd@0.5sec"
        - "psd@1sec"
      -
        - "psd@0.5sec"
        - "psd@2sec"
      -
        - "psd@0.5sec"
        - "psd@5sec"
      -
        - "psd@1sec"
        - "psd@2sec"
      -
        - "psd@1sec"
        - "psd@5sec"
      -
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@1sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@2sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@1sec"
        - "psd@2sec"
      -
        - "psd@0.2sec"
        - "psd@1sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.5sec"
        - "psd@1sec"
        - "psd@2sec"
      -
        - "psd@0.5sec"
        - "psd@1sec"
        - "psd@5sec"
      -
        - "psd@0.5sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@1sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@1sec"
        - "psd@2sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@1sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@1sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.5sec"
        - "psd@1sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
        - "psd@0.5sec"
        - "psd@1sec"
        - "psd@2sec"
        - "psd@5sec"
      -
        - "psd@0.2sec"
      -
        - "psd@0.5sec"
      -
        - "psd@1sec"
      -
        - "psd@2sec"
      -
        - "psd@5sec"
    