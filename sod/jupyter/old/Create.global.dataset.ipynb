{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oneminutewindows.id', 'modified', 'window_type', 'start_time', 'length_sec']\n",
      "['magnitudeenergy.id', 'subclass']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import os, pandas as pd, numpy as np\n",
    "from joblib import dump, load\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "# from sod.core.evaluation import normalize\n",
    "import sod.core.dataset as sod_core_dataset\n",
    "importlib.reload(sod_core_dataset)\n",
    "import sod.core.plot as sod_plot\n",
    "importlib.reload(sod_plot)\n",
    "# from sod.core.dataset import open_dataset # , normalize_df\n",
    "# from sod import plot\n",
    "isoutl = sod_core_dataset.is_outlier\n",
    "\n",
    "dataframe1 = sod_core_dataset.open_dataset('oneminutewindows.hdf', normalize=False, verbose=False)\n",
    "dataframe2 = sod_core_dataset.open_dataset('magnitudeenergy.hdf', normalize=False, verbose=False)\n",
    "\n",
    "print([_ for _ in dataframe1.columns if _ not in dataframe2.columns])\n",
    "print([_ for _ in dataframe2.columns if _ not in dataframe1.columns])\n",
    "\n",
    "\n",
    "# clf_iso_cont_5perc = load(os.path.abspath(os.path.join(os.getcwd(), '..', 'evaluations', 'results', 'cv.oneminutewindows.iforest.yaml',\n",
    "#                          'IsolationForest?features=psd@2sec,psd@5sec&contamination=0.005&max_samples=16384&n_estimators=100&behaviour=new.model')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Copriamo tutti i casi: frequenze basse e frequenze medio alte (locali)\n",
    "# psd0.2 psd5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "outl. (wrong inv)\n",
      "outl. (cha. resp. acc <-> vel)\n",
      "outl. (gain X100 or X0.01)\n",
      "outl. (gain X10 or X0.1)\n",
      "outl. (gain X2 or X0.5)\n",
      "unlabeled (Me suspicious outl.)\n",
      "\n",
      "All columns (same for both datasets):\n",
      "Index(['Segment.db.id', 'dataset_id', 'psd@0.05sec', 'psd@0.1sec',\n",
      "       'psd@0.2sec', 'psd@0.5sec', 'psd@1sec', 'psd@2sec', 'psd@3sec',\n",
      "       'psd@5sec', 'psd@9sec', 'outlier', 'subclass', 'window_type',\n",
      "       'amplitude_ratio', 'event_id', 'station_id', 'event_time',\n",
      "       'channel_code', 'magnitude', 'distance_km'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sod_core_dataset)\n",
    "from sod.core.dataset import magnitudeenergy, oneminutewindows, is_outlier, globalset\n",
    "from sod.core import pdconcat\n",
    "\n",
    "df1 = dataframe1.copy()\n",
    "df2 = dataframe2.copy()\n",
    "\n",
    "s2sid = 'Segment.db.id'\n",
    "train_dfs = []\n",
    "tests_dfs = []\n",
    "\n",
    "df1.rename(columns={'oneminutewindows.id': s2sid, 'modified': globalset._SUBCLASS_COL}, inplace=True)\n",
    "df1.insert(1, 'dataset_id', 1)\n",
    "df1['dataset_id'] = df1['dataset_id'].astype(int) \n",
    "df1.drop(['start_time', 'length_sec'], 1, inplace=True)\n",
    "# take from dataframe1 only noise and signals:\n",
    "tmp_df1 = df1[~df1.window_type.str.match('^ns$')]\n",
    "assert 3*len(tmp_df1)/2 == len(df1)\n",
    "df1 = tmp_df1\n",
    "\n",
    "df2.rename(columns={'magnitudeenergy.id': s2sid} , inplace=True)\n",
    "df2.insert(1, 'dataset_id', 2)\n",
    "df2['dataset_id'] = df2['dataset_id'].astype(int)\n",
    "assert not df2.loc[magnitudeenergy.class_selector['unlabeled (unknown)'], 'outlier'].any()\n",
    "assert df2.loc[magnitudeenergy.class_selector['unlabeled (suspicious outl.)'], 'outlier'].all()\n",
    "df2[globalset._WINDOW_TYPE_COL] = ''\n",
    "\n",
    "# build train: from dataframe1: inlier, and wrong inventory\n",
    "globaldf = pdconcat([df1, df2])\n",
    "expected = False\n",
    "for cname in globalset.classnames:\n",
    "    print(cname)\n",
    "    assert (globaldf.loc[globalset.class_selector[cname], 'outlier'] == expected).all()\n",
    "    expected = True\n",
    "\n",
    "assert len(globaldf) > len(df1) and len(globaldf) > len(df2)\n",
    "\n",
    "print('\\nAll columns (same for both datasets):')\n",
    "print (globaldf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sod.core.evaluation import save_df\n",
    "\n",
    "save_df(globaldf, '/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/globalset.hdf', key='globalset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
