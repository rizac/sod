{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The purpose of this notebook is to check which features might be best, i.e., they separate better the data. This is in order to avoid to iterate over all combinations of the features and saving time.\n",
    "Each point on a plot represents a <b>segment</b>.\n",
    "<br>\n",
    "Take these results very carefully for two reasons: we have a total of around 1400 segments, less than 10% of the data we will process, and visual inspection is ok but is no matenatical proof\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /Users/riccardo/work/gfz/projects/sources/python/sod/sod/dataset/dataset.hdf\n",
      "\n",
      "                                instances\n",
      "ok                                331,121\n",
      "outl. (wrong inv. file)             1,452\n",
      "outl. (cha. resp. acc <-> vel)    393,777\n",
      "outl. (gain X100 or X0.01)        331,121\n",
      "outl. (gain X10 or X0.1)          331,121\n",
      "outl. (gain X2 or X0.5)           331,121\n",
      "total                           1,719,713\n",
      "\n",
      "Normalizing numeric columns (floats only)\n",
      "                   min median   max      NAs segs1-99 stas1-99\n",
      "snr               0.00   0.00  1.00   11,542    6,566      367\n",
      "magnitude         0.00   0.40  1.00        0    7,869      355\n",
      "distance_km       0.00   0.35  1.00        0    6,624      351\n",
      "amp@0.5hz         -inf   0.62  1.94   13,899    6,612      254\n",
      "amp@1hz           -inf   0.64  2.05   12,384    6,618      263\n",
      "amp@2hz           -inf   0.63  2.11   11,799    6,622      253\n",
      "amp@5hz           -inf   0.45  2.69   11,630    6,622      223\n",
      "amp@10hz          -inf   0.54  2.42   11,606    6,622      173\n",
      "amp@20hz          -inf   0.53  2.41   11,553    6,622      166\n",
      "noise_psd@1sec    0.00   0.96  1.08       40    6,624      196\n",
      "noise_psd@2sec    0.00   0.97  1.08      106    6,622      193\n",
      "noise_psd@3sec    0.00   0.97  1.08      283    6,622      195\n",
      "noise_psd@5sec    0.00   0.96  1.08      300    6,622      195\n",
      "noise_psd@9sec    0.00   0.96  1.02  118,800    6,438      185\n",
      "amplitude_ratio   0.00   0.00  1.00        0    6,648       88\n",
      "pga              -0.22   0.35  2.55   11,330    6,568      268\n",
      "pgv              -0.18   0.34  2.09   11,330    6,568      284\n",
      "delta_pga        -0.19   0.43  2.49   11,330    6,568      347\n",
      "delta_pgv        -0.20   0.45  2.50   11,330    6,568      341\n",
      "-------\n",
      "Min and max might be outside [0, 1] because the normalization \n",
      "bounds are calculated on good segments (non outlier) only\n",
      "NAs: values which are NaN or Infinity\n",
      "segs1-99: unique segments (not outliers) outside 1 percentile\n",
      "stas1-99: unique stations of the segments in segs1-99\n",
      "\n",
      "During the operation, the following warning(s) were issued:\n",
      "/Users/riccardo/work/gfz/projects/sources/python/sod/sod/evaluation/__init__.py:156: RuntimeWarning: divide by zero encountered in log10\n",
      "  dfr[col] = np.log10(dfr[col])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd, numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from sod.evaluation import open_dataset\n",
    "\n",
    "o_dataframe = open_dataset(os.path.join(os.getcwd(), '..', 'dataset', 'dataset.hdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping dataset per station\n",
      "(For floating columns, the median of all segments stations will be set)\n",
      "\n",
      "num_segments  num_stations\n",
      "        [1, 5)           138\n",
      "       [5, 10)            71\n",
      "     [10, 100)           500\n",
      "    [100, 500)           765\n",
      "   [500, 1000)           324\n",
      "  [1000, 5000)           462\n",
      " [5000, 10000)            23\n",
      "[10000, 10081)             3\n",
      "\n",
      "Summary of the new dataset (instances are now stations\n",
      "                               instances\n",
      "ok                                   282\n",
      "outl. (wrong inv. file)                5\n",
      "outl. (cha. resp. acc <-> vel)       325\n",
      "outl. (gain X100 or X0.01)           558\n",
      "outl. (gain X10 or X0.1)             558\n",
      "outl. (gain X2 or X0.5)              558\n",
      "total                              2,286\n",
      "\n",
      "During the operation, the following warning(s) were issued:\n",
      "/Users/riccardo/work/gfz/projects/sources/python/sod/.env/sod/lib/python3.7/site-packages/numpy/lib/function_base.py:3250: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "/Users/riccardo/work/gfz/projects/sources/python/sod/.env/sod/lib/python3.7/site-packages/numpy/lib/nanfunctions.py:908: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sod.evaluation import groupby_stations\n",
    "\n",
    "dataframe = groupby_stations(o_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sod.evaluation import is_outlier\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "PLOT_RATIO = 1  # there is too much data, show only this ratio\n",
    "LOW_SNR = False\n",
    "\n",
    "def plot(df, col_x, col_y, col_z=None, axis_lim=None):\n",
    "    '''axis_lim is the quantile of data to be shown on the axis: 0.95 will display the axis min and max\n",
    "    at 0.05 quantile of the data distribution and 0.95 quantile, respectuvely'''\n",
    "    if LOW_SNR:\n",
    "        df = df[df['snr'] > 3]\n",
    "    is_outl = is_outlier(df)\n",
    "    df = df[:int(len(df) * PLOT_RATIO)]\n",
    "    # df = df[(~df['low_snr']) & ~(df['saturated'])]\n",
    "    df_ok = df[~is_outl]\n",
    "    df_no = df[is_outl]\n",
    "    \n",
    "    if axis_lim is None:\n",
    "        minx, maxx = (df[col_x]).min(), (df[col_x]).max()\n",
    "        miny, maxy = (df[col_y]).min(), (df[col_y]).max()\n",
    "        minz, maxz = (None, None)\n",
    "        if col_z is not None:\n",
    "            miny, maxy = (df[col_z]).min(), (df[col_z]).max()\n",
    "    else:\n",
    "        minx, maxx = df[col_x].quantile([1-axis_lim, axis_lim])\n",
    "        miny, maxy = df[col_y].quantile([1-axis_lim, axis_lim])\n",
    "        minz, maxz = (None, None)\n",
    "        if col_z is not None:\n",
    "            minz, maxz = df[col_z].quantile([1-axis_lim, axis_lim])\n",
    "\n",
    "    \n",
    "    # divide the dataframe in bins. Take PLOT_RATIO randomly points for each bin\n",
    "    indices = set()\n",
    "    for c in [col_x, col_y] + ([] if col_z is None else [col_z]):\n",
    "        bins = pd.cut(df[c], 10)\n",
    "        for _, df_ in df.groupby(bins):\n",
    "            if df_.empty:\n",
    "                continue\n",
    "            num = int(len(df_) * PLOT_RATIO)\n",
    "            if num < 1:\n",
    "                num = 1\n",
    "            indices |= set(df_.sample(num).index.values)\n",
    "    \n",
    "    l = len(df)\n",
    "    df = df.loc[list(indices), : ]\n",
    "    print(\"%d -> %d \" % (len(df), l))\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    def newaxes(index):\n",
    "        row, col = 3, 3\n",
    "        if col_z is not None:\n",
    "            ax = fig.add_subplot(row, col, index, projection='3d')\n",
    "        else:\n",
    "            ax = fig.add_subplot(row, col, index)\n",
    "        ax.set_xlim(minx, maxx)\n",
    "        ax.set_ylim(miny, maxy)\n",
    "        ax.set_xlabel(col_x)\n",
    "        ax.set_ylabel(col_y)\n",
    "        if col_z is not None:\n",
    "            ax.set_zlabel(col_z)\n",
    "            ax.set_zlim(minz, maxz)\n",
    "        ax.grid(True)\n",
    "        return ax\n",
    "    \n",
    "    def scatter(ax, df, color):\n",
    "        kwargs = {'edgecolors': 'none', 's': 81}\n",
    "        if col_z is None:\n",
    "            ax.scatter(df[col_x], df[col_y], color=color, **kwargs)\n",
    "        else:\n",
    "            ax.scatter(df[col_x], df[col_y], df[col_z], color=color, **kwargs)\n",
    "        \n",
    "    alpha = 0.1\n",
    "    \n",
    "    ax = newaxes(1)\n",
    "    scatter(ax, df_ok, [0, 0.1, 0.75, alpha])\n",
    "    ax.set_title('GOOD: %d segs' % len(df_ok))\n",
    "    \n",
    "    ax = newaxes(2)\n",
    "    df_no_ = df_no[df_no['modified'].str.contains('CHARESP')]\n",
    "    scatter(ax, df_no_, [0.75, 0.1, 0, alpha])\n",
    "    ax.set_title('BAD (CH.RESP. SWITCH ACC<->VEL): %d segs' % len(df_no_))\n",
    "\n",
    "    ax = newaxes(3)\n",
    "    df_no_ = df_no[df_no['modified'].str.contains('INVFILE:')]\n",
    "    scatter(ax, df_no_, [0, 0.75, 0.1, alpha])\n",
    "    ax.set_title('BAD (WRONG INVENTORY): %d segs' % len(df_no_))\n",
    "    \n",
    "    color = [0.75, 0.5, 0, alpha]\n",
    "\n",
    "    for i, label in enumerate([\n",
    "        'STAGEGAIN:X100.0',\n",
    "        'STAGEGAIN:X10.0',\n",
    "        'STAGEGAIN:X2.0',\n",
    "        'STAGEGAIN:X0.01',\n",
    "        'STAGEGAIN:X0.1',\n",
    "        'STAGEGAIN:X0.5'\n",
    "    ], 4):\n",
    "        ax = newaxes(i)\n",
    "        df_no_ = df_no[df_no['modified'].str.contains(label)]\n",
    "        scatter(ax, df_no_, color)\n",
    "        ax.set_title('BAD (%s): %d segs' % (label, len(df_no_)))\n",
    "    \n",
    "#     ax = newaxes(5)\n",
    "#     df_no_ = df_no[df_no['modified'].str.contains('STAGEGAIN:X10.0')]\n",
    "#     scatter(ax, df_no_, color)\n",
    "#     ax.set_title('BAD (GAINx5): %d segs' % len(df_no_))\n",
    "    \n",
    "#     ax = newaxes(6)\n",
    "#     df_no_ = df_no[df_no['modified'].str.contains('STAGEGAIN:X2.0')]\n",
    "#     scatter(ax, df_no_, color)\n",
    "#     ax.set_title('BAD (GAINx2): %d segs' % len(df_no_))\n",
    "    \n",
    "#     ax = newaxes(7)\n",
    "#     df_no_ = df_no[df_no['modified'].str.contains('STAGEGAIN:X0.1')]\n",
    "#     scatter(ax, df_no_, color)\n",
    "#     ax.set_title('BAD (GAIN/10): %d segs' % len(df_no_))\n",
    "    \n",
    "#     ax = newaxes(8)\n",
    "#     df_no_ = df_no[df_no['modified'].str.contains('STAGEGAIN:X0.2')]\n",
    "#     scatter(ax, df_no_, color)\n",
    "#     ax.set_title('BAD (GAIN/5): %d segs' % len(df_no_))\n",
    "    \n",
    "#     ax = newaxes(9)\n",
    "#     df_no_ = df_no[df_no['modified'].str.contains('STAGEGAIN:X0.5')]\n",
    "#     scatter(ax, df_no_, color)\n",
    "#     ax.set_title('BAD (GAIN/2): %d segs' % len(df_no_))\n",
    "    \n",
    "    space = .4 if col_z is not None else .25\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=space, hspace=space)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>First try: PGA vs PGV. Observations on the plots below:\n",
    "    <ul>\n",
    "        <li> The symmetry of data along the line y=x (roughly speaking) seems to show that calculations are consistent. Still, you can see how two features separate the data better than a single one (try to project the point on either the x or y axis, and you see that the data blue vs rest is not very separable)\n",
    "        <li>Changing the gain by a factor of 2,5,10 (bottom plots, yellow) does not change a lot with respect to the good ones (first plot, blue). As expected, the distribution of x10 (first bottom plot on the left) says something more than the other two\n",
    "    </ul></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dataframe, 'pga', 'pgv', axis_lim=.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ok let's replace PGV with psd@10sec on the y axis. Observations on the plots below:\n",
    "    <ul>\n",
    "        <li>psd@10sec seems to well separate the good vs bad data (plots on the first row).\n",
    "        <li>Still, changing the gain by a factor of 2,5,10 (bottom plots, yellow) does not change a lot with respect to the good ones (first plot, blue)\n",
    "    </ul>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(dataframe, 'pga', 'noise_psd@5sec', axis_lim=.97)  # with delta_pgv does not change a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What if we use log10(pga) instead of delta_pga?\n",
    "    <!-- <ul>\n",
    "        <li>At low periods we have more antropic noise, but apparently if we have a really wrong inventory (first row of plots) psd@0.1sec seem to perform as psd@10sec for good vs bad data (plots on the first row).\n",
    "        <li>But, changing the gain by a factor of 2,5,10 (bottom plots, yellow) does not change a lot with respect to the good ones (first plot, blue), and in this case psd@10sec performs better\n",
    "    </ul> -->\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dataframe, 'noise_psd@1sec', 'noise_psd@5sec', axis_lim=.98)  # with delta_pgv does not change a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "# FROM NOW ON WE CAN DELETE STUFF!!!!!\n",
    "\n",
    "# ALL WHAT IS DONE BELOW IS OUTDATED!!!!!\n",
    "\n",
    "# CHECKIT\n",
    "# CHECKIT!!!!!\n",
    "\n",
    "\n",
    "\n",
    "dfr = dataframe[['pga_observed', 'pgv_observed', 'outlier', 'modified']].copy()\n",
    "dfr['pga_observed'] = np.log10(dfr['pga_observed'].abs())\n",
    "dfr['pgv_observed'] = np.log10(dfr['pgv_observed'].abs())\n",
    "plot(dfr, 'pga_observed', 'pgv_observed', axis_lim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What if we add snr?\n",
    "    <!-- <ul>\n",
    "        <li>At low periods we have more antropic noise, but apparently if we have a really wrong inventory (first row of plots) psd@0.1sec seem to perform as psd@10sec for good vs bad data (plots on the first row).\n",
    "        <li>But, changing the gain by a factor of 2,5,10 (bottom plots, yellow) does not change a lot with respect to the good ones (first plot, blue), and in this case psd@10sec performs better\n",
    "    </ul> -->\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dataframe, 'noise_psd@2sec', 'noise_psd@5sec', axis_lim=.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What if we use psd@0.1sec (the shortest period we have). Let's replace PGA with psd@0.1sec on the x axis. Observations on the plots below:\n",
    "    <ul>\n",
    "        <li>At low periods we have more antropic noise, but apparently if we have a really wrong inventory (first row of plots) psd@0.1sec seem to perform as psd@10sec for good vs bad data (plots on the first row).\n",
    "        <li>But, changing the gain by a factor of 2,5,10 (bottom plots, yellow) does not change a lot with respect to the good ones (first plot, blue), and in this case psd@10sec performs better\n",
    "    </ul>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dataframe, 'noise_psd@1sec', 'noise_psd@9sec', axis_lim=.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Another try (not shown, irrelevant): let's psd@10sec (the lagest period we have) with some information on the signal (psd refers to the noise). Becasue psd is on the largest period, I take also the amplitude spectrum on the largest frequency (amp@10hz), \n",
    "    using the log10 of the amplitudes (Dino observation, ask why) <b>But let's keep in mind that the earthquake amplitude is a function of magnitude and distance</b>, so these plots are just a try. Observations on the plots below:\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Last try: let's try to summarize the three most promising features\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dforig.copy(), 'delta_pga', 'delta_pgv', 'psd@10sec', axis_lim=.99)  # with delta_pgv does not change a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to try:\n",
    "    1. normalization\n",
    "    \n",
    "    2. All combinations:\n",
    "\n",
    "    delta_pga\n",
    "    delta_pgv\n",
    "    psd@10sec\n",
    "    delta_pga, delta_pgv,\n",
    "    delta_pga, delta_pgv, psd@10sec,\n",
    "    delta_pga, psd@10sec, snr\n",
    "    delta_pga, delta_pgv, snr\n",
    "    delta_pga, delta_pgv, psd@10sec, snr\n",
    "    \n",
    "    then without other info, only spectral information:\n",
    "    distance_km, magnitude, amp@0.5hz, amp@1hz, amp@2hz, amp@5hz, amp@10hz\n",
    "    distance_km, magnitude, amp@0.5hz, amp@1hz, amp@2hz, amp@5hz, amp@10hz, snr\n",
    "    distance_km, magnitude, amp@0.5hz, amp@1hz, amp@2hz, amp@5hz, amp@10hz, psd@10Hz, snr\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
