{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, sys, yaml\n",
    "from stream2segment.process.db import get_session\n",
    "from stream2segment.io.db.models import Station, Segment, concat, Channel\n",
    "from stream2segment.io.utils import loads_inv\n",
    "# # warnings.simplefilter('always')\n",
    "# _fle = os.path.abspath(os.path.join('.', 'jnconfig.yaml'))\n",
    "# assert os.path.isfile(_fle)\n",
    "# with open(_fle, \"r\") as _:\n",
    "#     jnconfig = yaml.safe_load(_)\n",
    "\n",
    "# # dbpath_old = jnconfig['dbpath_old']\n",
    "# dbpath = jnconfig['dbpath_new']\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "from sod.core.dataset import open_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "_dfr = pd.read_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/globalset.hdf')\n",
    "_dfr_loc_d1 = pd.read_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/oneminutewindows.hdf.loccode.hdf')\n",
    "_dfr_loc_d2 = pd.read_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/magnitudeenergy.hdf.loccode.hdf')\n",
    "_dfr_chile = pd.read_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/cx_chile.hdf')\n",
    "\n",
    "_dfr_d1 = pd.read_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/oneminutewindows_sn_only.hdf')\n",
    "_dfr_d2 = pd.read_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/magnitudeenergy.hdf')\n",
    "\n",
    "\n",
    "# dataframe_old = dataframe.copy()\n",
    "# dataframe = open_dataset('globalset', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = _dfr.copy()\n",
    "dfr_loc_d1 = _dfr_loc_d1.copy()\n",
    "dfr_loc_d2 = _dfr_loc_d2.copy()\n",
    "dfr_chile = _dfr_chile.copy()\n",
    "dfr_d1 = _dfr_d1.copy()\n",
    "dfr_d2 = _dfr_d2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "globalset columns:\n",
      "Index(['Segment.db.id', 'dataset_id', 'psd@0.05sec', 'psd@0.1sec',\n",
      "       'psd@0.2sec', 'psd@0.5sec', 'psd@1sec', 'psd@2sec', 'psd@3sec',\n",
      "       'psd@5sec', 'psd@9sec', 'outlier', 'subclass', 'window_type',\n",
      "       'amplitude_ratio', 'event_id', 'station_id', 'event_time',\n",
      "       'channel_code', 'magnitude', 'distance_km'],\n",
      "      dtype='object')\n",
      "\n",
      "loccha oneminutewindows columns\n",
      "Index(['Segment.db.id', 'location_code'], dtype='object')\n",
      "\n",
      "loccha magnitudeenergy columns\n",
      "Index(['Segment.db.id', 'location_code'], dtype='object')\n",
      "\n",
      "chile columns\n",
      "Index(['psd@0.05sec', 'psd@0.1sec', 'psd@0.2sec', 'psd@0.5sec', 'psd@1sec',\n",
      "       'psd@2sec', 'psd@3sec', 'psd@5sec', 'psd@9sec', 'outlier',\n",
      "       'amplitude_ratio', 'event_id', 'station_id', 'event_time',\n",
      "       'channel_code', 'location_code', 'magnitude', 'distance_km',\n",
      "       'Segment.db.id'],\n",
      "      dtype='object')\n",
      "['Segment.db.id', 'amplitude_ratio', 'channel_code', 'distance_km', 'event_id', 'event_time', 'magnitude', 'outlier', 'psd@0.05sec', 'psd@0.1sec', 'psd@0.2sec', 'psd@0.5sec', 'psd@1sec', 'psd@2sec', 'psd@3sec', 'psd@5sec', 'psd@9sec', 'station_id']\n",
      "['Segment.db.id', 'amplitude_ratio', 'channel_code', 'distance_km', 'event_id', 'event_time', 'magnitude', 'outlier', 'psd@0.05sec', 'psd@0.1sec', 'psd@0.2sec', 'psd@0.5sec', 'psd@1sec', 'psd@2sec', 'psd@3sec', 'psd@5sec', 'psd@9sec', 'station_id']\n",
      "\n",
      "**********************************\n",
      "DATASET ID == 2 IS MAGNITUDEENERGY\n",
      "**********************************\n",
      "Unique window_type(s) of globalset: \n",
      "['n' 's' '']\n",
      "Unique subclass(s) of globalset: \n",
      "['' 'STAGEGAIN:X0.01' 'STAGEGAIN:X0.1' 'STAGEGAIN:X0.5' 'STAGEGAIN:X2.0'\n",
      " 'STAGEGAIN:X10.0' 'STAGEGAIN:X100.0' 'CHARESP:LHZ' 'CHARESP:LHN'\n",
      " 'CHARESP:LHE' 'CHARESP:HHZ' 'CHARESP:HHN' 'CHARESP:HHE' 'CHARESP:BHZ'\n",
      " 'CHARESP:BHN' 'CHARESP:BHE' 'CHARESP:HNZ' 'CHARESP:HNE' 'CHARESP:HNN'\n",
      " 'INVFILE:FR.PYLO.2010-01-17T10:00:00.xml' 'CHARESP:VHE' 'CHARESP:VHN'\n",
      " 'CHARESP:VHZ' 'CHARESP:EHE' 'CHARESP:EHN' 'CHARESP:EHZ' 'CHARESP:HLE'\n",
      " 'CHARESP:HLN' 'CHARESP:HLZ' 'INVFILE:CH.GRIMS.2015-10-30T10:50:00.xml'\n",
      " 'CHARESP:HGE' 'CHARESP:HGN' 'CHARESP:HGZ'\n",
      " 'INVFILE:CH.GRIMS.2011-11-09T00:00:00.xml' 'CHARESP:SHZ' 'CHARESP:SNE'\n",
      " 'CHARESP:SNN' 'CHARESP:SNZ' 'CHARESP:SHE' 'CHARESP:SHN'\n",
      " 'INVFILE:SK.MODS.2004-03-17T00:00:00.xml'\n",
      " 'INVFILE:SK.ZST.2004-03-17T00:00:00.xml' 'CHARESP:BNZ' 'CHARESP:LNZ'\n",
      " 'CHARESP:LNN' 'CHARESP:BNN' 'CHARESP:LNE' 'CHARESP:BNE'\n",
      " 'unlabeled.unknown' 'unlabeled.maybe.outlier']\n"
     ]
    }
   ],
   "source": [
    "# some assertions:\n",
    "ID = 'Segment.db.id'  #'globalset.id'\n",
    "LOC = 'location_code'\n",
    "\n",
    "assert LOC not in dfr.columns\n",
    "assert LOC in dfr_loc_d1.columns\n",
    "assert LOC in dfr_loc_d2.columns\n",
    "assert LOC in dfr_chile.columns\n",
    "\n",
    "assert ID in dfr.columns\n",
    "assert ID in dfr_loc_d1.columns\n",
    "assert ID in dfr_loc_d2.columns\n",
    "assert ID in dfr_chile.columns\n",
    "\n",
    "print('\\nglobalset columns:')\n",
    "print(dfr.columns)\n",
    "print('\\nloccha oneminutewindows columns')\n",
    "print(dfr_loc_d1.columns)\n",
    "print('\\nloccha magnitudeenergy columns')\n",
    "print(dfr_loc_d2.columns)\n",
    "print('\\nchile columns')\n",
    "print(dfr_chile.columns)\n",
    "\n",
    "col1 = (_ for _ in dfr.columns if _ not in ('subclass', 'window_type', 'dataset_id'))\n",
    "col2 = (_ for _ in dfr_chile.columns if _ != LOC)\n",
    "\n",
    "print(sorted(col1))\n",
    "print(sorted(col2))\n",
    "\n",
    "assert sorted(col1) == sorted(col2)\n",
    "\n",
    "assert sorted(dfr_loc_d1.columns.tolist()) == [ID, LOC]\n",
    "assert sorted(dfr_loc_d2.columns.tolist()) == [ID, LOC]\n",
    "\n",
    "channelz = pd.unique(dfr[dfr.dataset_id==2]['channel_code']).tolist()\n",
    "assert channelz == ['BHZ']\n",
    "\n",
    "channelz = pd.unique(dfr[dfr.dataset_id==1]['channel_code']).tolist()\n",
    "assert len(channelz) > 1\n",
    "\n",
    "\n",
    "channelz = pd.unique(dfr_chile['channel_code']).tolist()\n",
    "# print(sorted(channelz))\n",
    "assert sorted(channelz) == ['BHE', 'BHN', 'BHZ', 'BLE', 'BLN', 'BLZ']\n",
    "assert ~(dfr_chile.outlier).any()\n",
    "\n",
    "print()\n",
    "print('**********************************')\n",
    "print('DATASET ID == 2 IS MAGNITUDEENERGY')\n",
    "print('**********************************')\n",
    "\n",
    "print('Unique window_type(s) of globalset: ')\n",
    "print(pd.unique(dfr.window_type))\n",
    "\n",
    "print('Unique subclass(s) of globalset: ')\n",
    "print(pd.unique(dfr.subclass))\n",
    "\n",
    "\n",
    "dfr_chile['window_type'] = ''\n",
    "dfr_chile['subclass'] = ''\n",
    "dfr_chile['dataset_id'] = 3\n",
    "\n",
    "dfr_loc_d1['dataset_id'] = 1\n",
    "dfr_loc_d2['dataset_id'] = 2\n",
    "\n",
    "dfr[LOC] = ''\n",
    "\n",
    "assert sorted(dfr.columns) == sorted(dfr_chile.columns)\n",
    "assert sorted(dfr_loc_d1.columns.tolist()) == [ID, 'dataset_id', LOC]\n",
    "assert sorted(dfr_loc_d2.columns.tolist()) == [ID, 'dataset_id', LOC]\n",
    "\n",
    "# assert sorted(dfr.columns.tolist()) == sorted(_ for _ in dfr_chile.columns if _ != LOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataset 1 locations into globalset\n",
      "Merging dataset 2 locations into globalset\n",
      "\n",
      "locations in dataset 1\n",
      "['01' '00' '']\n",
      "\n",
      "locations in dataset 2\n",
      "['' '00' 'BT' '10' '01' '02' '15' '51' '60' '06' '04' '03' '07' '05' '50'\n",
      " '55' '20' '30' '40' '80' '70']\n",
      "\n",
      "locations in dataset 3\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df, did in zip([dfr_loc_d1, dfr_loc_d2], [1, 2]):\n",
    "    print('Merging dataset %d locations into allset' % did)\n",
    "    dfr = dfr.merge(df, how='left', on=[ID, 'dataset_id'], validate='m:1')\n",
    "    # now dfr should have LOC + '_x' and LOC + '_y'\n",
    "    assert LOC + '_x' in dfr.columns and LOC + '_y' in dfr.columns\n",
    "    tobeset = dfr[ID].isin(df[ID]) & (dfr.dataset_id == did)\n",
    "    dfr.loc[tobeset, LOC] = dfr[LOC + '_y']\n",
    "    dfr.loc[~tobeset, LOC] = dfr[LOC + '_x']\n",
    "    dfr.drop([LOC+'_x', LOC+'_y'], axis=1, inplace=True)\n",
    "\n",
    "allset = pd.concat([dfr, dfr_chile], sort=False, axis=0, copy=True)\n",
    "\n",
    "print('\\nlocations in dataset 1')\n",
    "print(pd.unique(allset.loc[allset.dataset_id==1, LOC]))\n",
    "print('\\nlocations in dataset 2')\n",
    "print(pd.unique(allset.loc[allset.dataset_id==2, LOC]))\n",
    "print('\\nlocations in dataset 3')\n",
    "print(pd.unique(allset.loc[allset.dataset_id==3, LOC]))\n",
    "\n",
    "for df, did in zip([dfr_loc_d1, dfr_loc_d2, dfr_chile], [1, 2, 3]):\n",
    "    locs1 = pd.unique(allset.loc[allset.dataset_id==did, LOC])\n",
    "    locs2 = pd.unique(df[LOC])\n",
    "    try:\n",
    "        assert sorted(locs1) == sorted(locs2)\n",
    "    except AssertionError:\n",
    "        assert sorted(locs1) == sorted(locs2.tolist() + [''])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# now save files:\n",
    "# dataframe.to_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/allset.hdf',\n",
    "#                 format='table', mode='w', key='allset')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset 1 (oneminutewindows) item(s) of first db id\n",
      "            event_time    psd@3sec  magnitude    psd@1sec window_type  event_id  psd@0.1sec channel_code  amplitude_ratio  station_id  outlier  Segment.db.id    psd@5sec  distance_km    psd@2sec    psd@9sec  psd@0.5sec  psd@0.2sec  psd@0.05sec\n",
      "0  2011-01-02 14:40:11 -150.907489        4.2 -135.168397           n     73468 -133.747422          EHN         0.004554         512    False       22740574 -162.001655   106.546261 -145.581222 -168.986145 -129.668991 -134.670527  -135.821416\n",
      "2  2011-01-02 14:40:11 -130.107018        4.2  -98.268779           s     73468  -96.245629          EHN         0.004554         512    False       22740574 -134.318056   106.546261 -118.620953 -134.014328  -81.439253  -84.732465  -111.035331\n",
      "3  2011-01-02 14:40:11 -204.174355        4.2 -188.449218           n     73468 -179.188137          EHN         0.004554         512     True       22740574 -208.025795   106.546261 -198.699748 -216.537140 -183.797248 -178.556030  -175.422947\n",
      "5  2011-01-02 14:40:11 -170.169459        4.2 -138.315634           s     73468 -136.289625          EHN         0.004554         512     True       22740574 -174.432776   106.546261 -158.637424 -174.023376 -121.477702 -124.767165  -150.317797\n",
      "6  2011-01-02 14:40:11 -171.525176        4.2 -155.632293           n     73468 -153.957565          EHN         0.004554         512     True       22740574 -182.433034   106.546261 -166.107723 -189.861237 -150.117998 -154.973370  -155.273467\n",
      "8  2011-01-02 14:40:11 -150.109446        4.2 -118.273694           s     73468 -116.250620          EHN         0.004554         512     True       22740574 -154.325716   106.546261 -138.622422 -154.015396 -101.442629 -104.735722  -131.038601\n",
      "9  2011-01-02 14:40:11 -156.996963        4.2 -141.235759           n     73468 -139.805263          EHN         0.004554         512     True       22740574 -168.070297   106.546261 -151.654799 -175.110535 -135.734756 -140.729570  -141.833144\n",
      "11 2011-01-02 14:40:11 -136.127737        4.2 -104.289774           s     73468 -102.266715          EHN         0.004554         512     True       22740574 -140.340510   106.546261 -124.641607 -140.034210  -87.460232  -90.753434  -117.056892\n",
      "allset same item(s)\n",
      "           event_time    psd@3sec  magnitude    psd@1sec window_type  event_id  psd@0.1sec channel_code  amplitude_ratio  station_id  outlier  Segment.db.id    psd@5sec  distance_km    psd@2sec    psd@9sec  psd@0.5sec  psd@0.2sec  psd@0.05sec\n",
      "0 2011-01-02 14:40:11 -150.907489        4.2 -135.168397           n     73468 -133.747422          EHN         0.004554         512    False       22740574 -162.001655   106.546261 -145.581222 -168.986145 -129.668991 -134.670527  -135.821416\n",
      "1 2011-01-02 14:40:11 -130.107018        4.2  -98.268779           s     73468  -96.245629          EHN         0.004554         512    False       22740574 -134.318056   106.546261 -118.620953 -134.014328  -81.439253  -84.732465  -111.035331\n",
      "2 2011-01-02 14:40:11 -204.174355        4.2 -188.449218           n     73468 -179.188137          EHN         0.004554         512     True       22740574 -208.025795   106.546261 -198.699748 -216.537140 -183.797248 -178.556030  -175.422947\n",
      "3 2011-01-02 14:40:11 -170.169459        4.2 -138.315634           s     73468 -136.289625          EHN         0.004554         512     True       22740574 -174.432776   106.546261 -158.637424 -174.023376 -121.477702 -124.767165  -150.317797\n",
      "4 2011-01-02 14:40:11 -171.525176        4.2 -155.632293           n     73468 -153.957565          EHN         0.004554         512     True       22740574 -182.433034   106.546261 -166.107723 -189.861237 -150.117998 -154.973370  -155.273467\n",
      "5 2011-01-02 14:40:11 -150.109446        4.2 -118.273694           s     73468 -116.250620          EHN         0.004554         512     True       22740574 -154.325716   106.546261 -138.622422 -154.015396 -101.442629 -104.735722  -131.038601\n",
      "6 2011-01-02 14:40:11 -156.996963        4.2 -141.235759           n     73468 -139.805263          EHN         0.004554         512     True       22740574 -168.070297   106.546261 -151.654799 -175.110535 -135.734756 -140.729570  -141.833144\n",
      "7 2011-01-02 14:40:11 -136.127737        4.2 -104.289774           s     73468 -102.266715          EHN         0.004554         512     True       22740574 -140.340510   106.546261 -124.641607 -140.034210  -87.460232  -90.753434  -117.056892\n",
      "\n",
      "dataset 2 (magnitudeenergy) item(s) of first db id\n",
      "           event_time   psd@3sec  magnitude    psd@1sec  event_id  psd@0.1sec channel_code  amplitude_ratio  station_id  outlier  Segment.db.id   psd@5sec   distance_km    psd@2sec    psd@9sec  psd@0.5sec  psd@0.2sec           subclass  psd@0.05sec\n",
      "0 2017-08-23 22:00:52 -137.37146        5.1 -147.636223      1294 -150.345749          BHZ         0.000038           6    False         839355 -135.87609  10510.067576 -144.205619 -155.072089 -136.859489 -135.750031  unlabeled.unknown          NaN\n",
      "allset same item(s)\n",
      "                 event_time   psd@3sec  magnitude    psd@1sec  event_id  psd@0.1sec channel_code  amplitude_ratio  station_id  outlier  Segment.db.id   psd@5sec   distance_km    psd@2sec    psd@9sec  psd@0.5sec  psd@0.2sec           subclass  psd@0.05sec\n",
      "3465738 2017-08-23 22:00:52 -137.37146        5.1 -147.636223      1294 -150.345749          BHZ         0.000038           6    False         839355 -135.87609  10510.067576 -144.205619 -155.072089 -136.859489 -135.750031  unlabeled.unknown          NaN\n",
      "\n",
      "dataset 3 (chile) item(s) of first db id\n",
      "           event_time    psd@3sec  magnitude  psd@1sec window_type  dataset_id  event_id  psd@0.1sec channel_code  amplitude_ratio  station_id  outlier location_code  Segment.db.id   psd@5sec  distance_km    psd@2sec    psd@9sec  psd@0.5sec  psd@0.2sec subclass  psd@0.05sec\n",
      "0 2014-12-28 12:59:38 -128.804309        3.5 -120.9204                       3         1 -100.476067          BHE         0.000617           1    False                            1 -130.89543   237.342511 -129.557248 -141.253226 -110.016368 -103.133102                   NaN\n",
      "allset same item(s)\n",
      "           event_time    psd@3sec  magnitude  psd@1sec window_type  dataset_id  event_id  psd@0.1sec channel_code  amplitude_ratio  station_id  outlier location_code  Segment.db.id   psd@5sec  distance_km    psd@2sec    psd@9sec  psd@0.5sec  psd@0.2sec subclass  psd@0.05sec\n",
      "0 2014-12-28 12:59:38 -128.804309        3.5 -120.9204                       3         1 -100.476067          BHE         0.000617           1    False                            1 -130.89543   237.342511 -129.557248 -141.253226 -110.016368 -103.133102                   NaN\n"
     ]
    }
   ],
   "source": [
    "print('\\ndataset 1 (oneminutewindows) item(s) of first db id')\n",
    "id_ = dfr_d1[ID].iloc[0]\n",
    "shared_columns = list(set(dfr_d1.columns) & set(allset.columns))\n",
    "print(dfr_d1[dfr_d1[ID] == id_][shared_columns].to_string())\n",
    "print('allset same item(s)')\n",
    "print(allset[(allset[ID] == id_) & (allset.dataset_id==1)][shared_columns].to_string())\n",
    "\n",
    "print('\\ndataset 2 (magnitudeenergy) item(s) of first db id')\n",
    "id_ = dfr_d2[ID].iloc[0]\n",
    "shared_columns = list(set(dfr_d2.columns) & set(allset.columns))\n",
    "print(dfr_d2[dfr_d2[ID] == id_][shared_columns].to_string())\n",
    "print('allset same item(s)')\n",
    "print(allset[(allset[ID] == id_) & (allset.dataset_id==2)][shared_columns].to_string())\n",
    "\n",
    "print('\\ndataset 3 (chile) item(s) of first db id')\n",
    "id_ = dfr_chile[ID].iloc[0]\n",
    "shared_columns = list(set(dfr_chile.columns) & set(allset.columns))\n",
    "print(dfr_chile[dfr_chile[ID] == id_][shared_columns].to_string())\n",
    "print('allset same item(s)')\n",
    "print(allset[(allset[ID] == id_) & (allset.dataset_id==3)][shared_columns].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique subclasses/window_type/datase_id/outlier/location_code in train:\n",
      "('', '', 2, False, '')\n",
      "('', '', 2, False, '00')\n",
      "('', '', 2, False, '10')\n",
      "('', '', 2, False, '20')\n",
      "('', '', 2, False, '50')\n",
      "('', '', 2, False, '60')\n",
      "('', '', 2, True, '')\n",
      "('', '', 2, True, '00')\n",
      "('', '', 3, False, '')\n",
      "('', 'n', 1, False, '')\n",
      "('', 'n', 1, False, '00')\n",
      "('', 'n', 1, False, '01')\n",
      "('', 's', 1, False, '')\n",
      "('', 's', 1, False, '00')\n",
      "('', 's', 1, False, '01')\n",
      "('INVFILE:CH.GRIMS.2011-11-09T00:00:00.xml', 'n', 1, True, '')\n",
      "('INVFILE:CH.GRIMS.2011-11-09T00:00:00.xml', 's', 1, True, '')\n",
      "('INVFILE:CH.GRIMS.2015-10-30T10:50:00.xml', 'n', 1, True, '')\n",
      "('INVFILE:CH.GRIMS.2015-10-30T10:50:00.xml', 's', 1, True, '')\n",
      "('INVFILE:FR.PYLO.2010-01-17T10:00:00.xml', 'n', 1, True, '00')\n",
      "('INVFILE:FR.PYLO.2010-01-17T10:00:00.xml', 's', 1, True, '00')\n",
      "('INVFILE:SK.MODS.2004-03-17T00:00:00.xml', 'n', 1, True, '')\n",
      "('INVFILE:SK.MODS.2004-03-17T00:00:00.xml', 's', 1, True, '')\n",
      "('INVFILE:SK.ZST.2004-03-17T00:00:00.xml', 'n', 1, True, '')\n",
      "('INVFILE:SK.ZST.2004-03-17T00:00:00.xml', 's', 1, True, '')\n",
      "('unlabeled.maybe.outlier', '', 2, True, '')\n",
      "('unlabeled.maybe.outlier', '', 2, True, '00')\n",
      "('unlabeled.unknown', '', 2, False, '')\n",
      "('unlabeled.unknown', '', 2, False, '00')\n",
      "('unlabeled.unknown', '', 2, False, '01')\n",
      "('unlabeled.unknown', '', 2, False, '02')\n",
      "('unlabeled.unknown', '', 2, False, '03')\n",
      "('unlabeled.unknown', '', 2, False, '04')\n",
      "('unlabeled.unknown', '', 2, False, '05')\n",
      "('unlabeled.unknown', '', 2, False, '06')\n",
      "('unlabeled.unknown', '', 2, False, '07')\n",
      "('unlabeled.unknown', '', 2, False, '10')\n",
      "('unlabeled.unknown', '', 2, False, '15')\n",
      "('unlabeled.unknown', '', 2, False, '30')\n",
      "('unlabeled.unknown', '', 2, False, '40')\n",
      "('unlabeled.unknown', '', 2, False, '50')\n",
      "('unlabeled.unknown', '', 2, False, '51')\n",
      "('unlabeled.unknown', '', 2, False, '55')\n",
      "('unlabeled.unknown', '', 2, False, '60')\n",
      "('unlabeled.unknown', '', 2, False, '70')\n",
      "('unlabeled.unknown', '', 2, False, '80')\n",
      "('unlabeled.unknown', '', 2, False, 'BT')\n",
      "\n",
      "Unique subclasses/window_type/datase_id/outlier/location_code in test:\n",
      "('CHARESP:BHE', 'n', 1, True, '')\n",
      "('CHARESP:BHE', 'n', 1, True, '00')\n",
      "('CHARESP:BHE', 's', 1, True, '')\n",
      "('CHARESP:BHE', 's', 1, True, '00')\n",
      "('CHARESP:BHN', 'n', 1, True, '')\n",
      "('CHARESP:BHN', 'n', 1, True, '00')\n",
      "('CHARESP:BHN', 's', 1, True, '')\n",
      "('CHARESP:BHN', 's', 1, True, '00')\n",
      "('CHARESP:BHZ', 'n', 1, True, '')\n",
      "('CHARESP:BHZ', 'n', 1, True, '00')\n",
      "('CHARESP:BHZ', 's', 1, True, '')\n",
      "('CHARESP:BHZ', 's', 1, True, '00')\n",
      "('CHARESP:BNE', 'n', 1, True, '')\n",
      "('CHARESP:BNE', 's', 1, True, '')\n",
      "('CHARESP:BNN', 'n', 1, True, '')\n",
      "('CHARESP:BNN', 's', 1, True, '')\n",
      "('CHARESP:BNZ', 'n', 1, True, '')\n",
      "('CHARESP:BNZ', 's', 1, True, '')\n",
      "('CHARESP:EHE', 'n', 1, True, '')\n",
      "('CHARESP:EHE', 's', 1, True, '')\n",
      "('CHARESP:EHN', 'n', 1, True, '')\n",
      "('CHARESP:EHN', 's', 1, True, '')\n",
      "('CHARESP:EHZ', 'n', 1, True, '')\n",
      "('CHARESP:EHZ', 's', 1, True, '')\n",
      "('CHARESP:HGE', 'n', 1, True, '')\n",
      "('CHARESP:HGE', 's', 1, True, '')\n",
      "('CHARESP:HGN', 'n', 1, True, '')\n",
      "('CHARESP:HGN', 's', 1, True, '')\n",
      "('CHARESP:HGZ', 'n', 1, True, '')\n",
      "('CHARESP:HGZ', 's', 1, True, '')\n",
      "('CHARESP:HHE', 'n', 1, True, '')\n",
      "('CHARESP:HHE', 'n', 1, True, '00')\n",
      "('CHARESP:HHE', 's', 1, True, '')\n",
      "('CHARESP:HHE', 's', 1, True, '00')\n",
      "('CHARESP:HHN', 'n', 1, True, '')\n",
      "('CHARESP:HHN', 'n', 1, True, '00')\n",
      "('CHARESP:HHN', 's', 1, True, '')\n",
      "('CHARESP:HHN', 's', 1, True, '00')\n",
      "('CHARESP:HHZ', 'n', 1, True, '')\n",
      "('CHARESP:HHZ', 'n', 1, True, '00')\n",
      "('CHARESP:HHZ', 's', 1, True, '')\n",
      "('CHARESP:HHZ', 's', 1, True, '00')\n",
      "('CHARESP:HLE', 'n', 1, True, '')\n",
      "('CHARESP:HLE', 's', 1, True, '')\n",
      "('CHARESP:HLN', 'n', 1, True, '')\n",
      "('CHARESP:HLN', 's', 1, True, '')\n",
      "('CHARESP:HLZ', 'n', 1, True, '')\n",
      "('CHARESP:HLZ', 's', 1, True, '')\n",
      "('CHARESP:HNE', 'n', 1, True, '')\n",
      "('CHARESP:HNE', 'n', 1, True, '00')\n",
      "('CHARESP:HNE', 'n', 1, True, '01')\n",
      "('CHARESP:HNE', 's', 1, True, '')\n",
      "('CHARESP:HNE', 's', 1, True, '00')\n",
      "('CHARESP:HNE', 's', 1, True, '01')\n",
      "('CHARESP:HNN', 'n', 1, True, '')\n",
      "('CHARESP:HNN', 'n', 1, True, '00')\n",
      "('CHARESP:HNN', 'n', 1, True, '01')\n",
      "('CHARESP:HNN', 's', 1, True, '')\n",
      "('CHARESP:HNN', 's', 1, True, '00')\n",
      "('CHARESP:HNN', 's', 1, True, '01')\n",
      "('CHARESP:HNZ', 'n', 1, True, '')\n",
      "('CHARESP:HNZ', 'n', 1, True, '00')\n",
      "('CHARESP:HNZ', 'n', 1, True, '01')\n",
      "('CHARESP:HNZ', 's', 1, True, '')\n",
      "('CHARESP:HNZ', 's', 1, True, '00')\n",
      "('CHARESP:HNZ', 's', 1, True, '01')\n",
      "('CHARESP:LHE', 'n', 1, True, '')\n",
      "('CHARESP:LHE', 'n', 1, True, '00')\n",
      "('CHARESP:LHE', 's', 1, True, '')\n",
      "('CHARESP:LHE', 's', 1, True, '00')\n",
      "('CHARESP:LHN', 'n', 1, True, '')\n",
      "('CHARESP:LHN', 'n', 1, True, '00')\n",
      "('CHARESP:LHN', 's', 1, True, '')\n",
      "('CHARESP:LHN', 's', 1, True, '00')\n",
      "('CHARESP:LHZ', 'n', 1, True, '')\n",
      "('CHARESP:LHZ', 'n', 1, True, '00')\n",
      "('CHARESP:LHZ', 's', 1, True, '')\n",
      "('CHARESP:LHZ', 's', 1, True, '00')\n",
      "('CHARESP:LNE', 'n', 1, True, '')\n",
      "('CHARESP:LNE', 's', 1, True, '')\n",
      "('CHARESP:LNN', 'n', 1, True, '')\n",
      "('CHARESP:LNN', 's', 1, True, '')\n",
      "('CHARESP:LNZ', 'n', 1, True, '')\n",
      "('CHARESP:LNZ', 's', 1, True, '')\n",
      "('CHARESP:SHE', 'n', 1, True, '')\n",
      "('CHARESP:SHE', 's', 1, True, '')\n",
      "('CHARESP:SHN', 'n', 1, True, '')\n",
      "('CHARESP:SHN', 's', 1, True, '')\n",
      "('CHARESP:SHZ', 'n', 1, True, '')\n",
      "('CHARESP:SHZ', 's', 1, True, '')\n",
      "('CHARESP:SNE', 'n', 1, True, '')\n",
      "('CHARESP:SNE', 's', 1, True, '')\n",
      "('CHARESP:SNN', 'n', 1, True, '')\n",
      "('CHARESP:SNN', 's', 1, True, '')\n",
      "('CHARESP:SNZ', 'n', 1, True, '')\n",
      "('CHARESP:SNZ', 's', 1, True, '')\n",
      "('CHARESP:VHE', 'n', 1, True, '')\n",
      "('CHARESP:VHE', 's', 1, True, '')\n",
      "('CHARESP:VHN', 'n', 1, True, '')\n",
      "('CHARESP:VHN', 's', 1, True, '')\n",
      "('CHARESP:VHZ', 'n', 1, True, '')\n",
      "('CHARESP:VHZ', 's', 1, True, '')\n",
      "('STAGEGAIN:X0.01', 'n', 1, True, '')\n",
      "('STAGEGAIN:X0.01', 'n', 1, True, '00')\n",
      "('STAGEGAIN:X0.01', 'n', 1, True, '01')\n",
      "('STAGEGAIN:X0.01', 's', 1, True, '')\n",
      "('STAGEGAIN:X0.01', 's', 1, True, '00')\n",
      "('STAGEGAIN:X0.01', 's', 1, True, '01')\n",
      "('STAGEGAIN:X0.1', 'n', 1, True, '')\n",
      "('STAGEGAIN:X0.1', 'n', 1, True, '00')\n",
      "('STAGEGAIN:X0.1', 'n', 1, True, '01')\n",
      "('STAGEGAIN:X0.1', 's', 1, True, '')\n",
      "('STAGEGAIN:X0.1', 's', 1, True, '00')\n",
      "('STAGEGAIN:X0.1', 's', 1, True, '01')\n",
      "('STAGEGAIN:X0.5', 'n', 1, True, '')\n",
      "('STAGEGAIN:X0.5', 'n', 1, True, '00')\n",
      "('STAGEGAIN:X0.5', 'n', 1, True, '01')\n",
      "('STAGEGAIN:X0.5', 's', 1, True, '')\n",
      "('STAGEGAIN:X0.5', 's', 1, True, '00')\n",
      "('STAGEGAIN:X0.5', 's', 1, True, '01')\n",
      "('STAGEGAIN:X10.0', 'n', 1, True, '')\n",
      "('STAGEGAIN:X10.0', 'n', 1, True, '00')\n",
      "('STAGEGAIN:X10.0', 'n', 1, True, '01')\n",
      "('STAGEGAIN:X10.0', 's', 1, True, '')\n",
      "('STAGEGAIN:X10.0', 's', 1, True, '00')\n",
      "('STAGEGAIN:X10.0', 's', 1, True, '01')\n",
      "('STAGEGAIN:X100.0', 'n', 1, True, '')\n",
      "('STAGEGAIN:X100.0', 'n', 1, True, '00')\n",
      "('STAGEGAIN:X100.0', 'n', 1, True, '01')\n",
      "('STAGEGAIN:X100.0', 's', 1, True, '')\n",
      "('STAGEGAIN:X100.0', 's', 1, True, '00')\n",
      "('STAGEGAIN:X100.0', 's', 1, True, '01')\n",
      "('STAGEGAIN:X2.0', 'n', 1, True, '')\n",
      "('STAGEGAIN:X2.0', 'n', 1, True, '00')\n",
      "('STAGEGAIN:X2.0', 'n', 1, True, '01')\n",
      "('STAGEGAIN:X2.0', 's', 1, True, '')\n",
      "('STAGEGAIN:X2.0', 's', 1, True, '00')\n",
      "('STAGEGAIN:X2.0', 's', 1, True, '01')\n"
     ]
    }
   ],
   "source": [
    "from sod.core.dataset import globalset\n",
    "\n",
    "def selector(d):\n",
    "    return (d['dataset_id'] == 3) | (d['dataset_id'] == 2) \\\n",
    "        | ((d['dataset_id'] == 1) & (d['subclass'].str.match('^$')) & (~d['outlier'])) \\\n",
    "        | ((d['dataset_id'] == 1) & (d['subclass'].str.contains('INVFILE:')))\n",
    "\n",
    "dftrain = allset[selector(allset)]\n",
    "dftest = allset[~selector(allset)]\n",
    "\n",
    "colz = ['subclass', 'window_type', 'dataset_id', 'outlier', LOC]\n",
    "print('\\nUnique subclasses/window_type/datase_id/outlier/location_code in train:')\n",
    "for colzz, _ in dftrain.groupby(colz):\n",
    "    print(str(colzz))\n",
    "\n",
    "print('\\nUnique subclasses/window_type/datase_id/outlier/location_code in test:')\n",
    "for colzz, _ in dftest.groupby(colz):\n",
    "    print(str(colzz))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save files:\n",
    "dftrain.to_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/allset_train.hdf',\n",
    "               format='table', mode='w', key='allset_train')\n",
    "\n",
    "dftest.to_hdf('/Users/riccardo/work/gfz/projects/sources/python/sod/sod/datasets/allset_test.hdf',\n",
    "               format='table', mode='w', key='allset_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
