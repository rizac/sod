# ==========================================================================
# stream2segment config file to tune the processing/visualization subroutine
# ==========================================================================
#
# This editable template defines the configuration parameters which will
# be accessible in the associated processing / visualization python file.
#
# You are free to implement here anything you need: there are no mandatory parameters but we
# strongly suggest to keep 'segment_select' and 'sn_windows', which add also special features
# to the GUI.

# NOTE: **this file is written in YAML syntax**, which uses Python-style indentation to
# indicate nesting, keep it in mind when editing. You can also use a more compact format that
# uses [] for lists and {} for maps/objects.
# For info see http://docs.ansible.com/ansible/latest/YAMLSyntax.html

# The parameter 'segment_select' defines which segments to be processed or visualized. PLEASE USE
# THIS PARAMETER. If missing, all segments will be loaded, including segment with no
# (or malformed) waveform data: this is in practically always useless and slows down considerably
# the processing or visualization routine. The selection is made via the list-like argument:
#
# segment_select:
#   <att>: "<expression>"
#   <att>: "<expression>"
#   ...
#
# where each <att> is a segment attribute and <expression> is a simplified SQL-select string
# expression. Example:
#
# 1. To select and work on segments with downloaded data (at least one byte of data):
# segment_select:
#   has_data: "true"
#
# 2. To select and work on segments of stations activated in 2017 only:
# segment_select:
#   station.start_time: "[2017-01-01, 2018-01-01T00:00:00)"
# (brackets denote intervals. Square brackets include end-points, round brackets exclude endpoints)
#
# 3. To select segments from specified ids, e.g. 1, 4, 342, 67 (e.g., ids which raised errors during
# a previous run and whose id where logged might need inspection in the GUI):
# segment_select:
#   id: "1 4 342 67"
#
# 4. To select segments whose event magnitude is greater than 4.2:
# segment_select:
#   event.magnitude: ">4.2"
# (the same way work the operators: =, >=, <=, <, !=)
#
# 5. To select segments with a particular channel sensor description:
# segment_select:
#   channel.sensor_description: "'GURALP CMG-40T-30S'"
# (note: for attributes with str values and spaces, we need to quote twice, as otherwise
# "GURALP CMG-40T-30S" would match 'GURALP' and 'CMG-40T-30S', but not the whole string.
# See attribute types below)
#
# The list of segment attribute names and types is:
#
# ============================= ==============================================================
# attribute                     Python type and (optional) description
# ============================= ==============================================================
# id                            int: segment (unique) db id
# event_distance_deg            float: distance between the segment's station and
#                               the event, in degrees
# event_distance_km             float: distance between the segment's station and
#                               the event, in km, assuming a perfectly spherical earth
#                               with a radius of 6371 km
# start_time                    datetime.datetime: the waveform data start time
# arrival_time                  datetime.datetime: the station's arrival time of the waveform.
#                               Value between 'start_time' and 'end_time'
# end_time                      datetime.datetime: the waveform data end time
# request_start                 datetime.datetime: the requested start time of the data
# request_end                   datetime.datetime: the requested end time of the data
# duration_sec                  float: the waveform data duration, in seconds
# missing_data_sec              float: the number of seconds of missing data, with respect
#                               to the requested time window. It might also be negative
#                               (more data received than requested). This parameter is useful
#                               when selecting segments: e.g., if we requested 5
#                               minutes of data and we want to process segments with at
#                               least 4 minutes of downloaded data, then:
#                               missing_data_sec: '< 60'
# missing_data_ratio            float: the portion of missing data, with respect
#                               to the request time window. It might also be negative
#                               (more data received than requested). This parameter is useful
#                               when selecting segments: e.g., if you want to process
#                               segments whose real time window is at least 90% of the
#                               requested one, then: missing_data_ratio: '< 0.1'
# sample_rate                   float: the waveform data sample rate.
#                               It might differ from the segment channel's sample_rate
# has_data                      boolean: tells if the segment has data saved (at least
#                               one byte of data). This parameter is useful when selecting
#                               segments (in most cases, almost necessary), e.g.:
#                               has_data: 'true'
# download_code                 int: the code reporting the segment download status. This
#                               parameter is useful to further refine the segment selection
#                               skipping beforehand segments with malformed data (code -2):
#                               has_data: 'true'
#                               download_code: '!=-2'
#                               (We omit all other codes because of no interest. For details,
#                               see Table 2 in https://doi.org/10.1785/0220180314#tb2)
# maxgap_numsamples             float: the maximum gap or overlap found in the waveform data,
#                               in number of points. If 0, the segment has no gaps/overlaps.
#                               Otherwise, if >=1: the segment has gaps, if <=-1: the segment
#                               has overlaps. Values in (-1, 1) are difficult to interpret: a
#                               rule of thumb is to consider half a point (> 0.5 or <-0.5)
#                               a gap / overlap.
#                               This parameter is useful when selecting segments: e.g.,
#                               to select segments with no gaps/overlaps, then:
#                               maxgap_numsamples: '(-0.5, 0.5)'
# seed_id                       str: the seed identifier in the typical format
#                               [Network.Station.Location.Channel]. For segments
#                               with waveform data, `data_seed_id` (see below) might be
#                               faster to fetch.
# data_seed_id                  str: same as 'segment.seed_id', but faster because it
#                               reads the value stored in the waveform data. The drawback
#                               is that this value is null for segments with no waveform data
# has_class                     boolean: tells if the segment has (at least one) class
#                               assigned
# data                          bytes: the waveform (raw) bytes data. Used by `segment.stream()`
# ----------------------------- ------------------------------------------------
# event                         object (attributes below)
# event.id                      int
# event.event_id                str: the id returned by the web service or catalog
# event.time                    datetime.datetime
# event.latitude                float
# event.longitude               float
# event.depth_km                float
# event.author                  str
# event.catalog                 str
# event.contributor             str
# event.contributor_id          str
# event.mag_type                str
# event.magnitude               float
# event.mag_author              str
# event.event_location_name     str
# ----------------------------- ------------------------------------------------
# channel                       object (attributes below)
# channel.id                    int
# channel.location              str
# channel.channel               str
# channel.depth                 float
# channel.azimuth               float
# channel.dip                   float
# channel.sensor_description    str
# channel.scale                 float
# channel.scale_freq            float
# channel.scale_units           str
# channel.sample_rate           float
# channel.band_code             str: the first letter of channel.channel
# channel.instrument_code       str: the second letter of channel.channel
# channel.orientation_code      str: the third letter of channel.channel
# channel.station               object: same as segment.station (see below)
# ----------------------------- ------------------------------------------------
# station                       object (attributes below)
# station.id                    int
# station.network               str: the station's network code, e.g. 'AZ'
# station.station               str: the station code, e.g. 'NHZR'
# station.netsta_code           str: the network + station code, concatenated with
#                               the dot, e.g.: 'AZ.NHZR'
# station.latitude              float
# station.longitude             float
# station.elevation             float
# station.site_name             str
# station.start_time            datetime.datetime
# station.end_time              datetime.datetime
# station.has_inventory         boolean: tells if the segment's station inventory has
#                               data saved (at least one byte of data).
#                               This parameter is useful when selecting segments: e.g.,
#                               to select only segments with inventory downloaded:
#                               station.has_inventory: 'true'
# station.datacenter            object (same as segment.datacenter, see below)
# ----------------------------- ------------------------------------------------
# datacenter                    object (attributes below)
# datacenter.id                 int
# datacenter.station_url        str
# datacenter.dataselect_url     str
# datacenter.organization_name  str
# ----------------------------- ------------------------------------------------
# download                      object (attributes below): the download execution
# download.id                   int
# download.run_time             datetime.datetime
# ----------------------------- ------------------------------------------------
# classes.id                    int: the id(s) of the classes assigned to the segment
# classes.label                 int: the label(s) of the classes assigned to the segment
# classes.description           int: the description(s) of the classes assigned to the
#                               segment
# ============================= ================================================
#
segment_select:
  has_data: 'true'
  maxgap_numsamples: '[-0.5, 0.5]'
  download_code: '!=-2'
  data_seed_id: '"CH.GRIMS..HHN"'
  # data_seed_id: '"AC.PUK..HHN" "BS.BLKB..HNN" "BS.VETAM..HNN" "CH.DIX..HGN" "CH.FUSIO..HGN" "CH.FUSIO..HHN" "CH.GRIMS..HHE" "CH.GRIMS..HHE" "CH.GRIMS..HHN" "CH.GRIMS..HHN" "CH.GRIMS..HHZ" "CH.GRIMS..HHZ" "CH.MMK..HGN" "CH.MUGIO..HHN" "CH.NALPS..HHN" "CL.ROD3.01.EHN" "CQ.OSC2.01.HHN" "FR.ESCA.00.HNN" "FR.ESCA.01.HHN" "FR.MON.00.HNN" "FR.MVIF.00.HHN" "FR.OGDI.00.HHN" "FR.PYLO.00.HNE" "FR.PYLO.00.HNN" "FR.PYLO.00.HNZ" "FR.SAOF.00.HNN" "GE.GVD..HHN" "GE.KARP..HHN" "GE.KARP..HNN" "GE.MATE..HHN" "GE.SANT..HHN" "GE.TIRR..HHN" "GU.ENR..HHN" "GU.FIVI..HNN" "GU.GORR..HHN" "GU.PZZ..HHN" "GU.SATI..HHN" "GU.SC2M..HHN" "HA.EPID..HHN" "HA.EREA..HHN" "HA.KARY..HHN" "HA.LOUT..HHN" "HA.MAKR..HHN" "HA.PROD..HHN" "HA.SNT1..HHN" "HC.FRMA..HHN" "HC.GVDS..HHN" "HC.KNDR..HHN" "HC.KSTL..HHN" "HI.KRI1..HNN" "HL.AMGA..HHN" "HL.ARG..HHN" "HL.ATH..HHN" "HL.DION..HHN" "HL.DION..HNN" "HL.GVD..HHN" "HL.GVD.00.HNN" "HL.JAN..HHN" "HL.KARP..HHN" "HL.KARP..HNN" "HL.KASA.00.HNN" "HL.KEK..HHN" "HL.LIA..HHN" "HL.LKR..HHN" "HL.MGNA.00.HNN" "HL.NEO..HHN" "HL.NOAC.00.HNN" "HL.PATC.00.HNN" "HL.PRK..HHN" "HL.PRK..HNN" "HL.SANT..HHN" "HL.SMG..HHN" "HL.VAM..HHN" "HL.YDRA.00.HNN" "HP.AMT.00.HHN" "HP.ANX..HHN" "HP.ANX..HNN" "HP.DRO..HHN" "HP.FSK..HNN" "HP.GUR..HHN" "HP.LTHK..HHN" "HP.PDO..HHN" "HP.PVO..HHN" "HP.SERG..HHN" "HT.CMBO..HHN" "HT.LKD2..HHN" "HT.NIS1..HHN" "HT.SOH..HHN" "HT.TSLK..HHN" "IV.ACER..HHN" "IV.AIO..HHN" "IV.APEC..HHN" "IV.ATCC..EHN" "IV.ATPC..HHN" "IV.ATPC..HNN" "IV.ATVO..HNN" "IV.BORM..HNN" "IV.BRMO..HHN" "IV.CAFE..HNN" "IV.CAFR..HHN" "IV.CAR1..HHN" "IV.DOI..HHN" "IV.FAGN..HHN" "IV.FIU..EHN" "IV.FNVD..HHN" "IV.FOSV..HNN" "IV.FRON..EHN" "IV.HCRL..HHN" "IV.IMI..HHN" "IV.LNSS..HHN" "IV.LTRZ..HNN" "IV.MABI..HHN" "IV.MCEL..HNN" "IV.MCRV..HHN" "IV.MGAB..HNN" "IV.MOMA..HHN" "IV.MRB1..HHN" "IV.MSAG..HHN" "IV.MSRU..HHN" "IV.MTCR..EHN" "IV.NOCI..HHN" "IV.NOV..HHN" "IV.NOVE..EHN" "IV.ORI..HHN" "IV.PALZ..HHN" "IV.PII..HHN" "IV.PIO1..HNN" "IV.PIPA..HHN" "IV.PR02..HHN" "IV.RCAV..EHN" "IV.RM05..HNN" "IV.RM10..EHN" "IV.RM10..HNN" "IV.RM28..EHN" "IV.ROVR..HHN" "IV.SCTE..HHN" "IV.SFI..HNN" "IV.SGRT..HHN" "IV.SIRI..HNN" "IV.SMA1..EHN" "IV.T0502..EHN" "IV.T0502..HNN" "IV.T0503..EHN" "IV.T0702..EHN" "IV.T0711..EHN" "IV.T0711..HNN" "IV.VARE..HHN" "IV.VITU..HHN" "IV.ZEN8..HNN" "KO.ARMT..HHN" "KO.BALB..HHN" "KO.BGKT..HHN" "KO.CAVI..HHN" "KO.CRLT..HHN" "KO.CTKS..HHN" "KO.CTYL..HHN" "KO.ERIK..HHN" "KO.EZN..HHN" "KO.GEMT..HHN" "KO.GULA..HHN" "KO.GURO..HHN" "KO.HRTX..HHN" "KO.KAVV..HHN" "KO.KCTX..HHN" "KO.KRBG..HHN" "KO.KURC..HHN" "KO.LAP..HHN" "KO.PHSR..HHN" "KO.RKY..HHN" "KO.SAUV..HHN" "KO.SLVT..HHN" "KO.YLV..HHN" "ME.KOME..HHN" "MN.BLY..HHN" "MN.BLY..HLN" "MN.PDG..HHN" "MN.PDG..HLN" "MN.TUE..HHN" "MN.TUE..HLN" "NI.AGOR..BHN" "NI.AGOR..HHN" "OT.TAR1..HHN" "OX.CGRP..HNN" "PZ.BRGZ..EHN" "PZ.EASY..EHN" "PZ.HYBL..EHN" "PZ.PIER..EHN" "PZ.SCRP..EHN" "RA.BELV.00.HNN" "SI.KOSI..HHN" "SK.MODS..HHE" "SK.MODS..HHN" "SK.MODS..HHZ" "SK.ZST..HHE" "SK.ZST..HHN" "SK.ZST..HHZ" "TU.BORA..HHN" "TV.A001..EHN" "TV.AT01..EHN" "TV.CCN3..EHN" "XW.W02.00.BHN" "XW.W03.00.HHN" "XW.W04.00.BHN" "XW.W04.00.HHN" "XW.W05.00.BHN" "XW.W05.00.HHN" "XW.W08.00.BHN" "XW.W12.00.HHN" "XW.W13.00.BHN" "XW.W14.00.HHN" "XW.W16.00.HHN" "XY.ERE.00.HHN" "XY.KOY.00.HHN" "XY.UMT.00.HHN" "YI.E01.00.BHN" "YI.E02.00.BHN" "YI.E05.00.BHN" "YI.E12.00.BHN" "YI.E20.00.BHN" "Z3.AMOE..HHN" "ZZ.AMOE..HHN" "ZZ.PARO..HHN" "ZZ.SIFN..HHN"'
  station.has_inventory: 'true'
  missing_data_sec: '<60'
  # id: '<300'
  # event.time: "(2014-01-01T00:00:00, 2014-12-31T23:59:59)"
  # event.latitude: "[24, 70]"
  # event.longitude: "[-11, 24]"

# List of station ids whose inventory has both accel. and veloc. (use a dict for faster search, dict values are supposed to be ignored)

station_ids_both_accel_veloc:
  3937:  "BS.BLKB.2012-11-20T00:00:00"
  5795:  "CH.DIX.1999-08-04T00:00:00"
  5796:  "CH.DIX.2010-06-24T00:00:00"
  5797:  "CH.DIX.2016-11-03T17:20:00"
  5824:  "CH.FUSIO.2005-12-01T00:00:00"
  5825:  "CH.FUSIO.2008-10-21T00:00:00"
  5826:  "CH.FUSIO.2017-08-16T19:00:00"
  5860:  "CH.MMK.2017-10-12T16:00:00"
  5861:  "CH.MMK.2018-07-02T13:00:00"
  5878:  "CH.NALPS.2017-08-24T10:00:00"
  516:  "CL.ROD3.2014-03-14T14:00:00"
  3502:  "CQ.OSC2.2015-07-17T00:00:00"
  674:  "FR.ESCA.2008-06-11T11:30:00"
  678:  "FR.ESCA.2012-03-28T10:10:00"
  681:  "FR.ESCA.2014-07-30T12:30:00"
  759:  "FR.MON.2008-08-13T10:30:00"
  760:  "FR.MON.2008-12-18T08:30:00"
  761:  "FR.MON.2010-01-07T10:30:00"
  707:  "FR.MON.2010-01-22T09:15:00"
  762:  "FR.MON.2016-06-27T12:00:00"
  814:  "FR.OGDI.2010-02-21T00:00:00"
  966:  "FR.SAOF.2008-02-01T10:51:00"
  967:  "FR.SAOF.2010-09-16T11:06:00"
  968:  "FR.SAOF.2018-09-12T10:32:00"
  969:  "FR.SAOF.2018-12-17T12:05:00"
  9811:  "GE.KARP.2009-11-25T00:00:00"
  9921:  "GE.TIRR.2003-10-13T00:00:00"
  3620:  "HL.AMGA.2012-05-30T00:00:00"
  3642:  "HL.GVD.2010-09-21T00:00:00"
  3655:  "HL.KARP.2009-11-24T00:00:00"
  3707:  "HL.PRK.2012-12-29T00:00:00"
  4199:  "IV.ACER.2007-07-05T12:00:00"
  4214:  "IV.APEC.2014-02-06T12:00:00"
  4249:  "IV.ATPC.2009-01-26T15:00:00"
  4300:  "IV.CAFE.2010-02-03T14:00:00"
  4664:  "IV.MOMA.2011-08-08T14:00:00"
  4674:  "IV.MRB1.2004-01-29T00:00:00"
  4675:  "IV.MRB1.2010-01-25T16:00:00"
  4686:  "IV.MSAG.2006-05-25T17:00:00"
  4831:  "IV.RM10.2009-04-07T00:00:00"
  4849:  "IV.RM28.2009-06-19T00:00:00"
  4867:  "IV.ROVR.2008-10-08T00:00:00"
  4919:  "IV.SGRT.2006-05-24T17:00:00"
  4978:  "IV.T0502.2011-05-25T00:00:00"
  4979:  "IV.T0503.2011-05-25T00:00:00"
  5097:  "IV.VITU.2014-03-21T17:00:00"
  5169:  "MN.BLY.2009-05-21T08:00:00"
  5170:  "MN.BLY.2017-12-13T12:00:00"
  5225:  "MN.TUE.2010-08-20T11:50:00"
  5226:  "MN.TUE.2017-07-26T09:02:00"
  5267:  "OX.CGRP.2016-01-01T00:00:00"

# List of station ids with a wrong inventory saved locally. Each id is mapped to a channel mapped in turn to the relative file name

station_ids_with_wrong_local_inventory:
  5831:
    CH.GRIMS..HHE: "CH.GRIMS.2011-11-09T00:00:00.xml"
    CH.GRIMS..HHN: "CH.GRIMS.2011-11-09T00:00:00.xml"
    CH.GRIMS..HHZ: "CH.GRIMS.2011-11-09T00:00:00.xml"
  5833:
    CH.GRIMS..HHE: "CH.GRIMS.2015-10-30T10:50:00.xml"
    CH.GRIMS..HHN: "CH.GRIMS.2015-10-30T10:50:00.xml"
    CH.GRIMS..HHZ: "CH.GRIMS.2015-10-30T10:50:00.xml"
  10179:
    SK.MODS..HHE: "SK.MODS.2004-03-17T00:00:00.xml"
    SK.MODS..HHN: "SK.MODS.2004-03-17T00:00:00.xml"
    SK.MODS..HHZ: "SK.MODS.2004-03-17T00:00:00.xml"
  10186:
    SK.ZST..HHE: "SK.ZST.2004-03-17T00:00:00.xml"
    SK.ZST..HHN: "SK.ZST.2004-03-17T00:00:00.xml"
    SK.ZST..HHZ: "SK.ZST.2004-03-17T00:00:00.xml"
  890:
    FR.PYLO.00.HNE: "FR.PYLO.2010-01-17T10:00:00.xml"
    FR.PYLO.00.HNN: "FR.PYLO.2010-01-17T10:00:00.xml"
    FR.PYLO.00.HNZ: "FR.PYLO.2010-01-17T10:00:00.xml"

# path to the local inventory files listed above (relative to the path the processing is executed)
inventories_dir: 'sod/dataset/inventories/s2s_2017_10'

# stage gains factors for programmatically creating "wrong" inventory responses by
# increasing / decreasing stage gain:
stage_gain_factors:
  - 0.01
  - 0.1
  - 0.5
  - 2.0
  - 10.0
  - 100.0

# frequencies interpolation values (Hz)
freqs_interp:
 - 0.5
 - 1
 - 2
 - 5
 - 10
 - 20

# psd interpolation values (in seconds):
psd_periods:
 - 0.05 # amp@20hz
 - 0.1  # amp@10hz 
 - 0.2  # amp@5hz
 - 0.5  # amp@2hz
 - 1    # amp@1hz
 - 2    # amp@0.5hz
 - 3 
 - 5 
 - 9
# - 100

# Settings for computing the 'signal' and 'noise' time windows on a segment waveform.
# From within the GUI, signal and noise windows will be visualized as shaded areas on the plot
# of the currently selected segment. If this parameter is missing, the areas will not be shown.
# This parameter can also be used to define the arguments of `segment.sn_windows()` (see associated
# python module help).
#
# Arrival time shift: shifts the calculated arrival time of
# each segment by the specified amount of time (in seconds). Negative values are allowed.
# The arrival time is used to split a segment into segment's noise (before the arrival time)
# and segment's signal (after)
#
# Signal window: specifies the time window of the segment's signal, in seconds from the
# arrival time. If not numeric it must be a 2-element numeric array, denoting the
# start and end points, relative to the squares cumulative of the segment's signal portion.
# E.g.: [0.05, 0.95] sets the signal window from the time the cumulative reaches 5% of its
# maximum, until the time it reaches 95% of its maximum.
# The segment's noise window will be set equal to the signal window (i.e., same duration) and
# shifted in order to always end on the segment's arrival time
sn_windows:
  arrival_time_shift: 0  # programmatically shifts the arrival time for every segment (in seconds)
  signal_window: [0.1, 0.9]  # either a number (in seconds) or interval relative to the % of the cumulative


# settings for the sn (signal-to-noise) spectra implemented in the associated python module
sn_spectra:
  taper:
    max_percentage: 0.05
    type: 'hann'
  smoothing_wlen_ratio: 0.05  # 0 for no smoothing
  type: 'amp'  # if 'pow', then power spectra are computed, otherwise if 'amp', amplitude spectra are computed
  
# settings for the pre-process function implemented in the associated python module
preprocess:
  remove_response_water_level: 60
  remove_response_output: 'ACC'
  bandpass_freq_max: 30  # the max frequency, in Hz:
  bandpass_max_nyquist_ratio: 0.9
  bandpass_corners: 2
  velocimeter_freq_min: 0.01

# other custom parameters used in the associated python module
amp_ratio_threshold: 0.8
snr_threshold: 3


# Advanced settings tuning the process routine:
advanced_settings:
  # Use parallel sub-processes to speed up the execution.
  multi_process: true
  # The number of sub-processes. If null, it is set as the the number of CPUs in the
  # system. This option is ignored if multi_process is false
  num_processes: null
  # Although each segment is processed one at a time, loading segments in chunks from the
  # database is faster: the number below defines the chunk size. If multi_process is true,
  # the chunk size also defines how many segments will be loaded in each python sub-process.
  # Increasing this number might speed up execution but increases the memory usage.
  # When null, the chunk size defaults to 1200 if the number N of
  # segments to be processed is > 1200, otherwise N/10.
  segments_chunksize: 1200
  # Optional arguments for the output writer. Ignored for CSV output, for HDF output see:
  # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.HDFStore.append.html
  # (the parameters 'append' and 'value' will be ignored, if given here)
  writer_options:
    chunksize: 1200
    # hdf needs a fixed length for all columns: for variable-length string columns,
    # you need to tell in advance how many bytes to allocate with 'min_itemsize'.
    # E.g., if you have two string columns 'col1' and 'col2' and you assume to store
    # at most 10 ASCII characters in 'col1' and 20 in 'col2', then:
    min_itemsize:
      modified: 45
      window_type: 3
      channel_code: 3
    #   col2: 20

# If you want to use the GUI as hand labelling tool (for e.g. supervised classification problems)
# or setup classes before processing, you can provide the parameter 'class_labels' which is a
# dictionary of label names mapped to their description. If provided, the labels will first be
# added to the database (updating the description, if the label name is already present) and
# then will show up in the GUI where one or more classes can be assigned to a given segment via
# check boxes. If missing, no class labels will show up in the GUI, unless already set by a
# previous config. Example:
#class_labels:
#  Discarded: "Segment which does not fall in any other cathegory (e.g., unknown artifacts)"
#  Unknown: "Segment which is either: unlabeled (not annotated) or unclassified"
#  Ok: "Segment with no artifact"
#  LowS2N: "Segment has a low signal-to-noise ratio"
#  Aftershock: "Segment with non overlapping multi-events recorded (aftershock)"
#  MultiEvent: "Segment with overlapping multi-events recorded (no aftershock)"
#  BadCoda: "Segment with a bad coda (bad decay)"
