# ==========================================================
# stream2segment config file to tune the download subroutine
# ==========================================================

# NOTE: **this file is written in YAML syntax**, which uses Python-style indentation to
# indicate nesting, keep it in mind when editing. You can also use a more compact format that
# uses [] for lists and {} for maps/objects.
# For info see http://docs.ansible.com/ansible/latest/YAMLSyntax.html


# Database url where to save data (currently supported are sqlite and postgresql).
# We suggest sqlite for small to medium data sizes or enough system RAM (as a rule of thumb:
# less than a million segments, or more than 8GB of RAM) and postgres
# otherwise (note that with postgres, the database must have been created beforehand).
# If sqlite, just write the path to your local file
# prefixed with 'sqlite:///' (e.g., 'sqlite:////home/myfolder/db.sqlite'): non-absolute
# paths will be relative to the config file path.
# If non-sqlite, the syntax is:
# dialect+driver://username:password@host:port/database
# E.g.: 'postgresql://smith:Hw_6,@mymachine.example.org/mydb'
# (for info see: http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls)
dburl: 'sqlite:///./db.sqlite'

# Limit to events / datacenters / station / channels on or after the specified start time. Specify a date or
# date-time in iso-format or an integer >=0 to denote the number of days before today at midnight.
# Example: start=1 and end=0 => fetch events occurred yesterday.
# Implementation details: 'start' is also a valid name for this parameter
starttime: 2015-01-01T00:00:00

# Limit to events / datacenters / station / channels on or before the specified end time. Specify a date or
# date-time in iso-format or an integer >=0 to denote the number of days before today at midnight.
# Example: start=1 and end=0 => fetch events occurred yesterday.
# Implementation details: 'end' is also a valid name for this parameter
endtime: 2018-12-31T23:59:59


# =======
# Events: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=14
# =======

# The event web service url to use. Supply
# a *full* url (up to and not including the first query character '?')
# or a path to a local file.
# The events list returned by the url or in the supplied file must be formatted as specified
# in https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=16
# or as isf (http://www.isc.ac.uk/standards/isf/download/isf.pdf), although the latter
# has limited support in this program (e.g., comments are not supported. Use at your own risk).
# Implementation details: 1. You can also type one of the following shortcut strings:
# "emsc": http://www.seismicportal.eu/fdsnws/event/1/query
# "isc": http://www.isc.ac.uk/fdsnws/event/1/query
# "iris": http://service.iris.edu/fdsnws/event/1/query
# "ncedc": http://service.ncedc.org/fdsnws/event/1/query
# "scedc": http://service.scedc.caltech.edu/fdsnws/event/1/query
# "usgs": http://earthquake.usgs.gov/fdsnws/event/1/query.
# 2. If providing an event list file, the file name (not the full path) will be used
# as catalog identifier: renaming the file and downloading again on the same database
# will result in the events and their segments being saved twice
eventws: 'http://seismicportal.eu/fdsnws/event/1/query'

# Limit to events with a latitude larger than or equal to the specified minimum.
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
# Implementation details: 'minlat' is also a valid name for this parameter
minlatitude: -30

# Limit to events with a latitude smaller than or equal to the specified maximum
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
# Implementation details: 'maxlat' is also a valid name for this parameter
maxlatitude: -15

# Limit to events with a longitude larger than or equal to the specified minimum
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
# Implementation details: 'minlon' is also a valid name for this parameter
minlongitude: -75

# Limit to events with a longitude smaller than or equal to the specified maximum
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
# Implementation details: 'maxlon' is also a valid name for this parameter
maxlongitude: -60

# Limit to events with depth more than the specified minimum.
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
mindepth: 1

# Limit to events with depth less than the specified maximum
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
maxdepth: 100

# Limit to events with a magnitude larger than the specified minimum
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
# Implementation details: 'minmag' is also a valid name for this parameter
minmagnitude: 4

# Limit to events with a magnitude smaller than the specified maximum
# This parameter is ignored if missing, set to null, or 'eventws' is given as file path
# Implementation details: 'maxmag' is also a valid name for this parameter
maxmagnitude: 5

# Additional event web search parameters. For info, see
# https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=14
# (parameters with support 'Optional' are not guaranteed to work). Note that the 'format' parameter,
# if missing, will be inferred (in most cases it defaults to 'text').
# Implementation details: The parameter is empty by default, uncomment the lines below
# or insert new ones. Remember that this is a YAML file, pay attention to indentation. 
eventws_params:
  # lat: 47.0
  # lon: 4.0
  # minradius: 17.0
  # maxradius: 21.0


# ====================
# Stations / Channels: https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=10
# ====================

# Limit the search to the specified channels (if missing, defaults to '*', i.e.: accept all channels)
# Wildcards '?' and '*' are recognized (https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf),
# as well as the operator '!' placed as first character to indicate logical NOT.
# Example: "!B*,BBB" accepts all channels NOT starting with "B" OR the channel "BBB"
# Implementation details: 'cha' or 'channels' are also valid names for the parameter. You can
# also specify a list/array of strings in yaml format instead of comma-separated strings.
# E.g., these are quivalent:
# channels: "A,B"
# cha: [ "A" , "B" ]
# channel:
#  - "A"
#  - "B"
channel:
 - "B??"
 
# Limit the search to the specified networks (see 'channel' parameter for details).
# Implementation details: 'net' or 'networks' are also valid names for the parameter.
network: 'CX'

# Limit the search to the specified stations (see 'channel' parameter for details).
# Implementation details: 'sta' or 'stations' are also valid names for the parameter.
station: '*'

# Limit the search to the specified locations (see 'channel' parameter for details).
# Implementation details: 'loc' or 'locations' are also valid names for the parameter.
location: '*'

# Limit the search to channels with at least the following sample rate (in Hz).
# The relative segments will *mot likely* (but not always) match the channel sample rate.
# Set to 0 or negative number to ignore the sampling rate
min_sample_rate: 0

# Update stations and channels metadata overwriting already saved stations or channels.
# When false, only metadata of new stations and channels will be saved on the database
update_metadata: false

# Download station inventories (xml format). Downloading inventories with
# update_metadata=false will not download again already saved inventories. Downloading
# inventories with update_metadata=true will re-download the inventories of all stations.
# You can always download inventories later by providing "only" as value (wihtout quotes)
# which will download inventories only, i.e. skipping all other download steps and ignoring
# all other parameters (except 'update_metadata').
# Implementation details: inventories will in any case be downloaded and saved on the database
# only for stations that have saved segments with data. 
inventory: true

# search radius: defines the criteria for selecting stations around events. It is a dict
# which can have either:
# 1) two arguments ('min', 'max') in order to select stations exactly or within 'min' and 'mag' degrees
# from each event location (min=0 is equivalent to a circular search area)
# 2) four arguments in order to select stations within a circular
# area whose radius is event's magnitude dependent:
#
#                   |
#     maxmag_radius +                oooooooooooo
#                   |              o
#                   |            o
#                   |          o
#     minmag_radius + oooooooo
#                   |
#                   ---------+-------+------------
#                         minmag   maxmag
# If minmag = maxmag = M, maxmag_radius will be used for events with magnitude >= M,
# minmag_radius otherwise
search_radius:
 # minmag: 6 # min magnitude
 # maxmag: 7 # max magnitude
 # minmag_radius: 3 # search radius for min mag (deg)
 # maxmag_radius: 3 # search radius for max mag (deg)
 min: 0  # min radius (deg)
 max: 5  # max radius (deg)


# ========================
# Data (waveform segments) https://www.fdsn.org/webservices/FDSN-WS-Specifications-1.1.pdf#page=8
# (reminder: inventory=only will skip waveform download, see 'inventory' above)
# ========================

# Dataselect web service to use (url). It *must* be FDSN compliant
# (so that the station URL can be retrieved automatically):
#   <site>/fdsnws/dataselect/<majorversion>/query. Examples:
#   https://service.iris.edu/fdsnws/dataselect/1/query or
#   service.iris.edu/fdsnws/dataselect/1/query  (scheme will default to 'http://').
#   An ending '/' or '?' will be removed from the url, if present.
# You can also type two special values:
# "iris" (shortcut for: https://service.iris.edu/fdsnws/dataselect/1/query) or
# "eida" (which will automatically fetch data from the urls of all EIDA datacenters).
# Implementation details: If the station web service(s) did not return data
# (e.g., connection problems), then the requested stations and channels will be fetched from the
# database. In this case, if the database is empty the download process will stop with an error
# message.
dataws: 'http://geofon.gfz-potsdam.de/fdsnws/dataselect/1/query'

# The model to be used to asses the travel times of a wave from
# the event location to each station location. Type a string denoting a file name (absolute path)
# of a custom model created by means of `s2s utils ttcreate` or one of the 4 built-in models:
#   ak135_ttp+: ak135 model precomputed for all ttp+ phases (P wave arrivals)
#   ak135_tts+: ak135 model precomputed for all tts+ phases (S wave arrivals)
#   iasp91_ttp+: iasp91 model precomputed for all ttp+ phases (P wave arrivals)
#   iasp91_tts+: iasp91 model precomputed for all tts+ phases (S wave arrivals)
# For each segment, the arrival time (travel time + event time) will be the pivot
# whereby the user sets up the download time window (see also 'timespan').
# Implementation details: the *max* error on the arrival times (assessed on a random set of points)
# using one of the precomputed models is in the order of 0.5 seconds. All builtin models
# assume receiver depth=0 for simplicity
traveltimes_model: 'ak135_ttp+'

# The segment's time span (i.e., the data time window to download): specify two positive floats denoting 
# the minutes to account for before and after the calculated arrival time. Note that 3.5 means
# 3 minutes 30 seconds, and that each segment window will be eventually rounded to the nearest
# second to avoid floating point errors when checking for segments to re-download because of a
# changed window.
timespan:
 - 1.0 # start time of the waveform segment to download, in minutes *before* the calculated arrival time.
 - 3.0 # end time of the waveform segment to download, in minutes *after* the calculated arrival time

# Set the credentials in order to download restricted data.
# IMPORTANT: You SHOULD NOT perform massive, time-consuming downloads when fetching restricted data,
# as the credentials validity might expire during the download execution (this is the case with EDIA tokens).
# Try narrowing the search in case (e.g. provide the network(s) or station(s) of interest only).
# This parameter can be:
# - a single string pointing to a token file for restricted data authorization if "dataws" is "eida") 
#   (https://geofon.gfz-potsdam.de/waveform/archive/auth/auth-overview.php). Non-absolute
#   paths will be relative to the config file they are written in.
# - a list of two strings denoting username and password
# when this parameter is null, or the empty string, only open (unrestricted) waveform data will
# be downloaded. When provided, restricted segments previously downloaded with no credentials
# (thus, with no waveform data) will be always re-downloaded regardless of the retry_* parameters.
restricted_data: ""

# Try to download again already saved segments with no waveform data because not found
# in the response. This is NOT the case when the server returns no data with an appropriate
# 'No Content' message, but when a successful response (usually '200: OK') does not contain
# the expected segment data. E.g., a multi-segment request returns some but not all requested
# segments.
retry_seg_not_found: true

# Try to download again already saved segments with no waveform data because of a
# general url error (e.g., no internet connection, timeout, ...)
retry_url_err: true

# Try to download again already saved segments with no waveform data because the response was
# malformed, i.e. not readable as MiniSeed
retry_mseed_err: false

# Try to download again already saved segments with no waveform data because of a client error
# (response code in [400,499])
retry_client_err: true

# Try to download again already saved segments with no waveform data because of a server error
# (response code in [500,599])
retry_server_err: true

# Try to download again already saved segments with no waveform data because the response data
# was completely outside the requested time span (see 'timespan' for details)
retry_timespan_err: true


# =====================================
# Advanced settings (for experts only) 
# =====================================

advanced_settings:
 # the routing service used to fetch the eida nodes and relative network/stations
 routing_service_url: "http://www.orfeus-eu.org/eidaws/routing/1/query"
 # size (in bytes) of each block of data requested when downloading until no data is available.
 # This setting holds for any kind of data downloaded (event, waveform or station metadata)
 # If 0 or negative, all data will be read in a single call (if 0, it will be converted to -1).
 download_blocksize: 1048576  # = 1024*1024
 # how many parallel threads to start when downloading (one thread per download)
 # If null, 0 or negative, it is automatically set according to the machine CPU
 max_thread_workers: 0
 # max time to wait (in seconds) for a single request while downloading events
 e_timeout: 120
 # max time to wait (in seconds) for a single request while downloading stations+channel metadata
 s_timeout: 120
 # max time to wait (in seconds) for a single request while downloading an inventory in xml format
 i_timeout: 60
 # max time to wait (in seconds) for a single request while downloading waveform data
 w_timeout: 30
 # the buffer size used when writing items (stations, segments, events, ...) to database.
 # Increasing this number usually speeds speed up database IO operations (also, we experienced
 # performance degradations when this number is below the range [30, 50]) but increases the memory
 # consumption. Note also that if a single item in the buffer cannot be inserted or updated
 # (e.g., integrity errors), all subsequent buffer items will also be discarded
 db_buf_size: 100
