# ==========================================================================
# stream2segment config file to tune the processing/visualization subroutine
# ==========================================================================
#
# This editable template defines the configuration parameters which will
# be accessible in the associated processing / visualization python file.
#
# You are free to implement here anything you need: there are no mandatory parameters but we
# strongly suggest to keep 'segment_select' and 'sn_windows', which add also special features
# to the GUI.

# NOTE: **this file is written in YAML syntax**, which uses Python-style indentation to
# indicate nesting, keep it in mind when editing. You can also use a more compact format that
# uses [] for lists and {} for maps/objects.
# For info see http://docs.ansible.com/ansible/latest/YAMLSyntax.html

# The parameter 'segment_select' defines which segments to be processed or visualized. PLEASE USE
# THIS PARAMETER. If missing, all segments will be loaded, including segment with no
# (or malformed) waveform data: this is in practically always useless and slows down considerably
# the processing or visualization routine. The selection is made via the list-like argument:
#
# segment_select:
#   <att>: "<expression>"
#   <att>: "<expression>"
#   ...
#
# where each <att> is a segment attribute and <expression> is a simplified SQL-select string
# expression. Example:
#
# 1. To select and work on segments with downloaded data (at least one byte of data):
# segment_select:
#   has_data: "true"
#
# 2. To select and work on segments of stations activated in 2017 only:
# segment_select:
#   station.start_time: "[2017-01-01, 2018-01-01T00:00:00)"
# (brackets denote intervals. Square brackets include end-points, round brackets exclude endpoints)
#
# 3. To select segments from specified ids, e.g. 1, 4, 342, 67 (e.g., ids which raised errors during
# a previous run and whose id where logged might need inspection in the GUI):
# segment_select:
#   id: "1 4 342 67"
#
# 4. To select segments whose event magnitude is greater than 4.2:
# segment_select:
#   event.magnitude: ">4.2"
# (the same way work the operators: =, >=, <=, <, !=)
#
# 5. To select segments with a particular channel sensor description:
# segment_select:
#   channel.sensor_description: "'GURALP CMG-40T-30S'"
# (note: for attributes with str values and spaces, we need to quote twice, as otherwise
# "GURALP CMG-40T-30S" would match 'GURALP' and 'CMG-40T-30S', but not the whole string.
# See attribute types below)
#
# The list of segment attribute names and types is:
#
# ============================= ==============================================================
# attribute                     Python type and (optional) description
# ============================= ==============================================================
# id                            int: segment (unique) db id
# event_distance_deg            float: distance between the segment's station and
#                               the event, in degrees
# event_distance_km             float: distance between the segment's station and
#                               the event, in km, assuming a perfectly spherical earth
#                               with a radius of 6371 km
# start_time                    datetime.datetime: the waveform data start time
# arrival_time                  datetime.datetime: the station's arrival time of the waveform.
#                               Value between 'start_time' and 'end_time'
# end_time                      datetime.datetime: the waveform data end time
# request_start                 datetime.datetime: the requested start time of the data
# request_end                   datetime.datetime: the requested end time of the data
# duration_sec                  float: the waveform data duration, in seconds
# missing_data_sec              float: the number of seconds of missing data, with respect
#                               to the requested time window. It might also be negative
#                               (more data received than requested). This parameter is useful
#                               when selecting segments: e.g., if we requested 5
#                               minutes of data and we want to process segments with at
#                               least 4 minutes of downloaded data, then:
#                               missing_data_sec: '< 60'
# missing_data_ratio            float: the portion of missing data, with respect
#                               to the request time window. It might also be negative
#                               (more data received than requested). This parameter is useful
#                               when selecting segments: e.g., if you want to process
#                               segments whose real time window is at least 90% of the
#                               requested one, then: missing_data_ratio: '< 0.1'
# sample_rate                   float: the waveform data sample rate.
#                               It might differ from the segment channel's sample_rate
# has_data                      boolean: tells if the segment has data saved (at least
#                               one byte of data). This parameter is useful when selecting
#                               segments (in most cases, almost necessary), e.g.:
#                               has_data: 'true'
# download_code                 int: the code reporting the segment download status. This
#                               parameter is useful to further refine the segment selection
#                               skipping beforehand segments with malformed data (code -2):
#                               has_data: 'true'
#                               download_code: '!=-2'
#                               (We omit all other codes because of no interest. For details,
#                               see Table 2 in https://doi.org/10.1785/0220180314#tb2)
# maxgap_numsamples             float: the maximum gap or overlap found in the waveform data,
#                               in number of points. If 0, the segment has no gaps/overlaps.
#                               Otherwise, if >=1: the segment has gaps, if <=-1: the segment
#                               has overlaps. Values in (-1, 1) are difficult to interpret: a
#                               rule of thumb is to consider half a point (> 0.5 or <-0.5)
#                               a gap / overlap.
#                               This parameter is useful when selecting segments: e.g.,
#                               to select segments with no gaps/overlaps, then:
#                               maxgap_numsamples: '(-0.5, 0.5)'
# seed_id                       str: the seed identifier in the typical format
#                               [Network.Station.Location.Channel]. For segments
#                               with waveform data, `data_seed_id` (see below) might be
#                               faster to fetch.
# data_seed_id                  str: same as 'segment.seed_id', but faster because it
#                               reads the value stored in the waveform data. The drawback
#                               is that this value is null for segments with no waveform data
# has_class                     boolean: tells if the segment has (at least one) class
#                               assigned
# data                          bytes: the waveform (raw) bytes data. Used by `segment.stream()`
# ----------------------------- ------------------------------------------------
# event                         object (attributes below)
# event.id                      int
# event.event_id                str: the id returned by the web service or catalog
# event.time                    datetime.datetime
# event.latitude                float
# event.longitude               float
# event.depth_km                float
# event.author                  str
# event.catalog                 str
# event.contributor             str
# event.contributor_id          str
# event.mag_type                str
# event.magnitude               float
# event.mag_author              str
# event.event_location_name     str
# ----------------------------- ------------------------------------------------
# channel                       object (attributes below)
# channel.id                    int
# channel.location              str
# channel.channel               str
# channel.depth                 float
# channel.azimuth               float
# channel.dip                   float
# channel.sensor_description    str
# channel.scale                 float
# channel.scale_freq            float
# channel.scale_units           str
# channel.sample_rate           float
# channel.band_code             str: the first letter of channel.channel
# channel.instrument_code       str: the second letter of channel.channel
# channel.orientation_code      str: the third letter of channel.channel
# channel.station               object: same as segment.station (see below)
# ----------------------------- ------------------------------------------------
# station                       object (attributes below)
# station.id                    int
# station.network               str: the station's network code, e.g. 'AZ'
# station.station               str: the station code, e.g. 'NHZR'
# station.netsta_code           str: the network + station code, concatenated with
#                               the dot, e.g.: 'AZ.NHZR'
# station.latitude              float
# station.longitude             float
# station.elevation             float
# station.site_name             str
# station.start_time            datetime.datetime
# station.end_time              datetime.datetime
# station.has_inventory         boolean: tells if the segment's station inventory has
#                               data saved (at least one byte of data).
#                               This parameter is useful when selecting segments: e.g.,
#                               to select only segments with inventory downloaded:
#                               station.has_inventory: 'true'
# station.datacenter            object (same as segment.datacenter, see below)
# ----------------------------- ------------------------------------------------
# datacenter                    object (attributes below)
# datacenter.id                 int
# datacenter.station_url        str
# datacenter.dataselect_url     str
# datacenter.organization_name  str
# ----------------------------- ------------------------------------------------
# download                      object (attributes below): the download execution
# download.id                   int
# download.run_time             datetime.datetime
# ----------------------------- ------------------------------------------------
# classes.id                    int: the id(s) of the classes assigned to the segment
# classes.label                 int: the label(s) of the classes assigned to the segment
# classes.description           int: the description(s) of the classes assigned to the
#                               segment
# ============================= ================================================
#
segment_select:
  has_data: 'true'
  maxgap_numsamples: '[-0.5, 0.5]'
  download_code: '!=-2'
  data_seed_id: '!=null'
  station.has_inventory: 'true'
  missing_data_sec: '<120'
  id: '16734740 16739852 15571737 2303846 8732087 6471312 12485487 12485488'  # FIRST TOW GOOD, THAN BAD/GOOD (WITH WRONG INVENTORY), THEN UNKNOWN
# THIS DEBUG FILE USES THE DEFAULT CONFIG BUT PROCESSES ONLY SIX SEGMENTS: 2 GOOD, 2 BAD AND 2 UNKNOWN
# TO GET THE IDS OF THOSE SEGMENTS I PERFORMED A SEARCH ON THE SOURCE DATABASE LIKE THIS:
# (CHANGE THE STATION ID ACCORDING TO THE LISTS BELOW. LIMIT 2 JUST TO BE SAFER)
#
# The first two good where obtained with:
# SELECT SEGMENTS.ID FROM SEGMENTS WHERE SEGMENTS.DATA_SEED_ID = 'AC.PUK..HHN' AND LENGTH(SEGMENTS.DATA) > 1000 LIMIT 2
# But note that they have inventory with no data thus they will not be written
# The second two good where obtained with:
# SELECT SEGMENTS.ID FROM SEGMENTS WHERE SEGMENTS.DATA_SEED_ID = 'CH.FUSIO..HGN' AND LENGTH(SEGMENTS.DATA) > 1000 LIMIT 2
# The bad/good (with wrong inventory) with
# select segments.id, segments.data, stations.inventory_xml from segments join channels on channels.id = segments.channel_id join stations on stations.id = channels.station_id
# where
#   stations.id = 5833 and
#    length(segments.data) > 0 and
#    length(stations.inventory_xml) > 0  and
#    segments.data_seed_id = 'CH.GRIMS..HHZ'
# limit 2
# The others by typing this, select the first two and hoping we do not fall into one of the other categories:
# select segments.id from segments where length(segments.data)>1000 and segments.data_seed_id is not null limit 10

# Assign a dataset id (integer) to be saved for each row of the hdf. this is also
# useful for uniquely identofying each segment when merging all hdfs: in this
# case each segment is uniquely identified by the columns
# 'Segment.db.id', 'dataset_id', 'window_type'
dataset_id: 1


# Settings for computing the 'signal' and 'noise' time windows on a segment waveform.
# Set signal_window to False to compute the features on the whole window with no split.
# If signal_window is True, each trace to be processed
# will be splitted in two (signal and noise part), thus doubling the available traces
# the HDF file column 'window_type' will tell you if the segment stems from a 
# only noise window (window_type=False) or contains signal (window_type=True, the defualt)
sn_windows:
  arrival_time_shift: -1  # ignored if signal_window is False, otherwsie programmatically shifts the arrival time for every segment (in seconds)
  signal_window: True  # If True, splits each segment into noise and signal, otherwise computes the whole segment


# dict of GOOD channels (the mapping to null values is meaningless, but YAML does not have a Set type so we use a dict)
# All segments from these stations will have the column 'outlier' set as False
# (this is the default for every segment) but also the column 'hand_labelled' set as True
good:
  "AC.PUK..HHN": null
  "BS.BLKB..HNN": null
  "BS.VETAM..HNN": null
  "CH.DIX..HGN": null
  "CH.FUSIO..HGN": null
  "CH.FUSIO..HHN": null
  "CH.GRIMS..HHE": null
  "CH.GRIMS..HHE": null
  "CH.GRIMS..HHN": null
  "CH.GRIMS..HHN": null
  "CH.GRIMS..HHZ": null
  "CH.GRIMS..HHZ": null
  "CH.MMK..HGN": null
  "CH.MUGIO..HHN": null
  "CH.NALPS..HHN": null
  "CL.ROD3.01.EHN": null
  "CQ.OSC2.01.HHN": null
  "FR.ESCA.00.HNN": null
  "FR.ESCA.01.HHN": null
  "FR.MON.00.HNN": null
  "FR.MVIF.00.HHN": null
  "FR.OGDI.00.HHN": null
  "FR.PYLO.00.HNE": null
  "FR.PYLO.00.HNN": null
  "FR.PYLO.00.HNZ": null
  "FR.SAOF.00.HNN": null
  "GE.GVD..HHN": null
  "GE.KARP..HHN": null
  "GE.KARP..HNN": null
  "GE.MATE..HHN": null
  "GE.SANT..HHN": null
  "GE.TIRR..HHN": null
  "GU.ENR..HHN": null
  "GU.FIVI..HNN": null
  "GU.GORR..HHN": null
  "GU.PZZ..HHN": null
  "GU.SATI..HHN": null
  "GU.SC2M..HHN": null
  "HA.EPID..HHN": null
  "HA.EREA..HHN": null
  "HA.KARY..HHN": null
  "HA.LOUT..HHN": null
  "HA.MAKR..HHN": null
  "HA.PROD..HHN": null
  "HA.SNT1..HHN": null
  "HC.FRMA..HHN": null
  "HC.GVDS..HHN": null
  "HC.KNDR..HHN": null
  "HC.KSTL..HHN": null
  "HI.KRI1..HNN": null
  "HL.AMGA..HHN": null
  "HL.ARG..HHN": null
  "HL.ATH..HHN": null
  "HL.DION..HHN": null
  "HL.DION..HNN": null
  "HL.GVD..HHN": null
  "HL.GVD.00.HNN": null
  "HL.JAN..HHN": null
  "HL.KARP..HHN": null
  "HL.KARP..HNN": null
  "HL.KASA.00.HNN": null
  "HL.KEK..HHN": null
  "HL.LIA..HHN": null
  "HL.LKR..HHN": null
  "HL.MGNA.00.HNN": null
  "HL.NEO..HHN": null
  "HL.NOAC.00.HNN": null
  "HL.PATC.00.HNN": null
  "HL.PRK..HHN": null
  "HL.PRK..HNN": null
  "HL.SANT..HHN": null
  "HL.SMG..HHN": null
  "HL.VAM..HHN": null
  "HL.YDRA.00.HNN": null
  "HP.AMT.00.HHN": null
  "HP.ANX..HHN": null
  "HP.ANX..HNN": null
  "HP.DRO..HHN": null
  "HP.FSK..HNN": null
  "HP.GUR..HHN": null
  "HP.LTHK..HHN": null
  "HP.PDO..HHN": null
  "HP.PVO..HHN": null
  "HP.SERG..HHN": null
  "HT.CMBO..HHN": null
  "HT.LKD2..HHN": null
  "HT.NIS1..HHN": null
  "HT.SOH..HHN": null
  "HT.TSLK..HHN": null
  "IV.ACER..HHN": null
  "IV.AIO..HHN": null
  "IV.APEC..HHN": null
  "IV.ATCC..EHN": null
  "IV.ATPC..HHN": null
  "IV.ATPC..HNN": null
  "IV.ATVO..HNN": null
  "IV.BORM..HNN": null
  "IV.BRMO..HHN": null
  "IV.CAFE..HNN": null
  "IV.CAFR..HHN": null
  "IV.CAR1..HHN": null
  "IV.DOI..HHN": null
  "IV.FAGN..HHN": null
  "IV.FIU..EHN": null
  "IV.FNVD..HHN": null
  "IV.FOSV..HNN": null
  "IV.FRON..EHN": null
  "IV.HCRL..HHN": null
  "IV.IMI..HHN": null
  "IV.LNSS..HHN": null
  "IV.LTRZ..HNN": null
  "IV.MABI..HHN": null
  "IV.MCEL..HNN": null
  "IV.MCRV..HHN": null
  "IV.MGAB..HNN": null
  "IV.MOMA..HHN": null
  "IV.MRB1..HHN": null
  "IV.MSAG..HHN": null
  "IV.MSRU..HHN": null
  "IV.MTCR..EHN": null
  "IV.NOCI..HHN": null
  "IV.NOV..HHN": null
  "IV.NOVE..EHN": null
  "IV.ORI..HHN": null
  "IV.PALZ..HHN": null
  "IV.PII..HHN": null
  "IV.PIO1..HNN": null
  "IV.PIPA..HHN": null
  "IV.PR02..HHN": null
  "IV.RCAV..EHN": null
  "IV.RM05..HNN": null
  "IV.RM10..EHN": null
  "IV.RM10..HNN": null
  "IV.RM28..EHN": null
  "IV.ROVR..HHN": null
  "IV.SCTE..HHN": null
  "IV.SFI..HNN": null
  "IV.SGRT..HHN": null
  "IV.SIRI..HNN": null
  "IV.SMA1..EHN": null
  "IV.T0502..EHN": null
  "IV.T0502..HNN": null
  "IV.T0503..EHN": null
  "IV.T0702..EHN": null
  "IV.T0711..EHN": null
  "IV.T0711..HNN": null
  "IV.VARE..HHN": null
  "IV.VITU..HHN": null
  "IV.ZEN8..HNN": null
  "KO.ARMT..HHN": null
  "KO.BALB..HHN": null
  "KO.BGKT..HHN": null
  "KO.CAVI..HHN": null
  "KO.CRLT..HHN": null
  "KO.CTKS..HHN": null
  "KO.CTYL..HHN": null
  "KO.ERIK..HHN": null
  "KO.EZN..HHN": null
  "KO.GEMT..HHN": null
  "KO.GULA..HHN": null
  "KO.GURO..HHN": null
  "KO.HRTX..HHN": null
  "KO.KAVV..HHN": null
  "KO.KCTX..HHN": null
  "KO.KRBG..HHN": null
  "KO.KURC..HHN": null
  "KO.LAP..HHN": null
  "KO.PHSR..HHN": null
  "KO.RKY..HHN": null
  "KO.SAUV..HHN": null
  "KO.SLVT..HHN": null
  "KO.YLV..HHN": null
  "ME.KOME..HHN": null
  "MN.BLY..HHN": null
  "MN.BLY..HLN": null
  "MN.PDG..HHN": null
  "MN.PDG..HLN": null
  "MN.TUE..HHN": null
  "MN.TUE..HLN": null
  "NI.AGOR..BHN": null
  "NI.AGOR..HHN": null
  "OT.TAR1..HHN": null
  "OX.CGRP..HNN": null
  "PZ.BRGZ..EHN": null
  "PZ.EASY..EHN": null
  "PZ.HYBL..EHN": null
  "PZ.PIER..EHN": null
  "PZ.SCRP..EHN": null
  "RA.BELV.00.HNN": null
  "SI.KOSI..HHN": null
  "SK.MODS..HHE": null
  "SK.MODS..HHN": null
  "SK.MODS..HHZ": null
  "SK.ZST..HHE": null
  "SK.ZST..HHN": null
  "SK.ZST..HHZ": null
  "TU.BORA..HHN": null
  "TV.A001..EHN": null
  "TV.AT01..EHN": null
  "TV.CCN3..EHN": null
  "XW.W02.00.BHN": null
  "XW.W03.00.HHN": null
  "XW.W04.00.BHN": null
  "XW.W04.00.HHN": null
  "XW.W05.00.BHN": null
  "XW.W05.00.HHN": null
  "XW.W08.00.BHN": null
  "XW.W12.00.HHN": null
  "XW.W13.00.BHN": null
  "XW.W14.00.HHN": null
  "XW.W16.00.HHN": null
  "XY.ERE.00.HHN": null
  "XY.KOY.00.HHN": null
  "XY.UMT.00.HHN": null
  "YI.E01.00.BHN": null
  "YI.E02.00.BHN": null
  "YI.E05.00.BHN": null
  "YI.E12.00.BHN": null
  "YI.E20.00.BHN": null
  "Z3.AMOE..HHN": null
  "ZZ.AMOE..HHN": null
  "ZZ.PARO..HHN": null
  "ZZ.SIFN..HHN": null

# psd interpolation values (in seconds):
psd_periods:
 - 0.05 # amp@20hz
 - 0.1  # amp@10hz 
 - 0.2  # amp@5hz
 - 0.5  # amp@2hz
 - 1    # amp@1hz
 - 2    # amp@0.5hz
 - 3 
 - 5 
 - 9
# - 100


# Advanced settings tuning the process routine:
advanced_settings:
  # Use parallel sub-processes to speed up the execution.
  multi_process: true
  # The number of sub-processes. If null, it is set as the the number of CPUs in the
  # system. This option is ignored if multi_process is false
  num_processes: null
  # Although each segment is processed one at a time, loading segments in chunks from the
  # database is faster: the number below defines the chunk size. If multi_process is true,
  # the chunk size also defines how many segments will be loaded in each python sub-process.
  # Increasing this number might speed up execution but increases the memory usage.
  # When null, the chunk size defaults to 1200 if the number N of
  # segments to be processed is > 1200, otherwise N/10.
  segments_chunksize: 1
  # Optional arguments for the output writer. Ignored for CSV output, for HDF output see:
  # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.HDFStore.append.html
  # (the parameters 'append' and 'value' will be ignored, if given here)
  writer_options:
    chunksize: 1
    # hdf needs a fixed length for all columns: for variable-length string columns,
    # you need to tell in advance how many bytes to allocate with 'min_itemsize'.
    # E.g., if you have two string columns 'col1' and 'col2' and you assume to store
    # at most 10 ASCII characters in 'col1' and 20 in 'col2', then:
    min_itemsize:
      channel_code: 3
      location_code: 3

# If you want to use the GUI as hand labelling tool (for e.g. supervised classification problems)
# or setup classes before processing, you can provide the parameter 'class_labels' which is a
# dictionary of label names mapped to their description. If provided, the labels will first be
# added to the database (updating the description, if the label name is already present) and
# then will show up in the GUI where one or more classes can be assigned to a given segment via
# check boxes. If missing, no class labels will show up in the GUI, unless already set by a
# previous config. Example:
#class_labels:
#  Discarded: "Segment which does not fall in any other cathegory (e.g., unknown artifacts)"
#  Unknown: "Segment which is either: unlabeled (not annotated) or unclassified"
#  Ok: "Segment with no artifact"
#  LowS2N: "Segment has a low signal-to-noise ratio"
#  Aftershock: "Segment with non overlapping multi-events recorded (aftershock)"
#  MultiEvent: "Segment with overlapping multi-events recorded (no aftershock)"
#  BadCoda: "Segment with a bad coda (bad decay)"
